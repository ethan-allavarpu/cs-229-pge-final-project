{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import plotly\n",
    "import tqdm as notebook_tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv(\n",
    "    \"../data/processed/x_train_w_OHE.csv\", index_col=0, dtype=str\n",
    ")\n",
    "x_test = pd.read_csv(\n",
    "    \"../data/processed/x_test_w_OHE.csv\", index_col=0, dtype=str\n",
    ")\n",
    "y_train = pd.read_csv(\n",
    "    \"../data/processed/y_train.csv\", index_col=0, dtype=float\n",
    ").squeeze(\"columns\").reset_index(drop=True)\n",
    "y_test = pd.read_csv(\n",
    "    \"../data/processed/y_test.csv\", index_col=0, dtype=float\n",
    ").squeeze(\"columns\").reset_index(drop=True)\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_train, y_train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>circuit_name</th>\n",
       "      <th>deenergize_time</th>\n",
       "      <th>restoration_time</th>\n",
       "      <th>key_communities</th>\n",
       "      <th>hftd_tier</th>\n",
       "      <th>total_affected</th>\n",
       "      <th>residential_affected</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>...</th>\n",
       "      <th>zip_is_96035</th>\n",
       "      <th>zip_is_96051</th>\n",
       "      <th>zip_is_96055</th>\n",
       "      <th>zip_is_96059</th>\n",
       "      <th>zip_is_96069</th>\n",
       "      <th>zip_is_96073</th>\n",
       "      <th>zip_is_96076</th>\n",
       "      <th>zip_is_96080</th>\n",
       "      <th>zip_is_96096</th>\n",
       "      <th>zip_is_96137</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>SWIFT2110</td>\n",
       "      <td>2019-10-10 00:05:00</td>\n",
       "      <td>2019-10-11 14:17:00</td>\n",
       "      <td>SAN JOSE, LIVERMORE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2232.0</td>\n",
       "      <td>2047.0</td>\n",
       "      <td>95148</td>\n",
       "      <td>-121.796959988177</td>\n",
       "      <td>37.3225680192999</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>STATION E EUREKA1105</td>\n",
       "      <td>2019-10-09 01:20:00</td>\n",
       "      <td>2019-10-09 23:10:00</td>\n",
       "      <td>EUREKA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1618.0</td>\n",
       "      <td>1264.0</td>\n",
       "      <td>95501</td>\n",
       "      <td>-124.180313467792</td>\n",
       "      <td>40.7934324220744</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804</th>\n",
       "      <td>SILVERADO</td>\n",
       "      <td>2021-08-17 18:22:00</td>\n",
       "      <td>2021-08-18 23:55:00</td>\n",
       "      <td>NAPA</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1815.0</td>\n",
       "      <td>1516.0</td>\n",
       "      <td>94574</td>\n",
       "      <td>-122.459110675812</td>\n",
       "      <td>38.4998179385502</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>OREGON TRAIL1103</td>\n",
       "      <td>2019-10-09 01:39:00</td>\n",
       "      <td>2019-10-11 11:32:00</td>\n",
       "      <td>REDDING, BELLA VISTA</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1706.0</td>\n",
       "      <td>1599.0</td>\n",
       "      <td>96003</td>\n",
       "      <td>-122.322060242415</td>\n",
       "      <td>40.619045588007</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1390</th>\n",
       "      <td>OREGON TRAIL</td>\n",
       "      <td>2020-10-22 03:23:00</td>\n",
       "      <td>2020-10-23 11:30:00</td>\n",
       "      <td>PALO CEDRO, REDDING</td>\n",
       "      <td>2.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>843.0</td>\n",
       "      <td>96003</td>\n",
       "      <td>-122.322060242415</td>\n",
       "      <td>40.619045588007</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 284 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              circuit_name      deenergize_time     restoration_time  \\\n",
       "452              SWIFT2110  2019-10-10 00:05:00  2019-10-11 14:17:00   \n",
       "443   STATION E EUREKA1105  2019-10-09 01:20:00  2019-10-09 23:10:00   \n",
       "1804             SILVERADO  2021-08-17 18:22:00  2021-08-18 23:55:00   \n",
       "340       OREGON TRAIL1103  2019-10-09 01:39:00  2019-10-11 11:32:00   \n",
       "1390          OREGON TRAIL  2020-10-22 03:23:00  2020-10-23 11:30:00   \n",
       "\n",
       "           key_communities hftd_tier total_affected residential_affected  \\\n",
       "452    SAN JOSE, LIVERMORE       2.0         2232.0               2047.0   \n",
       "443                 EUREKA       0.0         1618.0               1264.0   \n",
       "1804                  NAPA       3.0         1815.0               1516.0   \n",
       "340   REDDING, BELLA VISTA       2.0         1706.0               1599.0   \n",
       "1390   PALO CEDRO, REDDING       2.0          952.0                843.0   \n",
       "\n",
       "     zip_code          longitude          latitude  ... zip_is_96035  \\\n",
       "452     95148  -121.796959988177  37.3225680192999  ...            0   \n",
       "443     95501  -124.180313467792  40.7934324220744  ...            0   \n",
       "1804    94574  -122.459110675812  38.4998179385502  ...            0   \n",
       "340     96003  -122.322060242415   40.619045588007  ...            0   \n",
       "1390    96003  -122.322060242415   40.619045588007  ...            0   \n",
       "\n",
       "     zip_is_96051 zip_is_96055 zip_is_96059 zip_is_96069 zip_is_96073  \\\n",
       "452             0            0            0            0            0   \n",
       "443             0            0            0            0            0   \n",
       "1804            0            0            0            0            0   \n",
       "340             0            0            0            0            0   \n",
       "1390            0            0            0            0            0   \n",
       "\n",
       "     zip_is_96076 zip_is_96080 zip_is_96096 zip_is_96137  \n",
       "452             0            0            0            0  \n",
       "443             0            0            0            0  \n",
       "1804            0            0            0            0  \n",
       "340             0            0            0            0  \n",
       "1390            0            0            0            0  \n",
       "\n",
       "[5 rows x 284 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_cols = x_train.columns[\n",
    "    [re.search('zip_is', col) is not None for col in x_train.columns]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correct_types_x(df, numeric_cols):\n",
    "    for col in ['deenergize_time', 'restoration_time']:\n",
    "        df[col] = pd.to_datetime(df[col], format='%Y-%m-%d %H:%M:%S')\n",
    "    for col in numeric_cols:\n",
    "        df[col] = df[col].astype(float)\n",
    "    return df\n",
    "\n",
    "\n",
    "numeric_cols = [\n",
    "    'hftd_tier', 'total_affected', 'residential_affected',\n",
    "    'longitude', 'latitude', 'total_pop', 'median_age', 'median_income',\n",
    "    'white_pct', 'tmin_d-5', 'tmax_d-5', 'wspd_d-5', 'tmin_d-4', 'tmax_d-4',\n",
    "    'wspd_d-4', 'tmin_d-3', 'tmax_d-3', 'wspd_d-3', 'tmin_d-2', 'tmax_d-2',\n",
    "    'wspd_d-2', 'tmin_d-1', 'tmax_d-1', 'wspd_d-1'\n",
    "]\n",
    "x_train = get_correct_types_x(x_train, numeric_cols)\n",
    "x_valid = get_correct_types_x(x_valid, numeric_cols)\n",
    "x_test = get_correct_types_x(x_test, numeric_cols)\n",
    "rel_x_train = x_train[numeric_cols]\n",
    "rel_x_valid = x_valid[numeric_cols]\n",
    "rel_x_test = x_test[numeric_cols]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(rel_x_train)\n",
    "scaled_x_train = scaler.transform(rel_x_train)\n",
    "scaled_x_valid = scaler.transform(rel_x_valid)\n",
    "scaled_x_test = scaler.transform(rel_x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class base_model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_hidden_layers, n_hidden_units, activation=torch.nn.ReLU()):\n",
    "        super(base_model, self).__init__()\n",
    "        if n_hidden_layers == 0:\n",
    "            self.linears =torch.nn.ModuleList([\n",
    "                torch.nn.Linear(scaled_x_train.shape[1], 1)\n",
    "            ])\n",
    "            self.activation = activation\n",
    "        else:\n",
    "            assert len(n_hidden_units) == n_hidden_layers\n",
    "            self.layers = []\n",
    "            \n",
    "            for layer, n_units in enumerate(n_hidden_units):\n",
    "                if layer == 0:\n",
    "                    curr_layer = torch.nn.Linear(scaled_x_train.shape[1], n_units)\n",
    "                else:\n",
    "                    curr_layer = torch.nn.Linear(n_hidden_units[layer - 1], n_units)\n",
    "                self.layers.append(curr_layer)\n",
    "            self.layers.append(torch.nn.Linear(n_hidden_units[-1], 1))\n",
    "            self.linears = torch.nn.ModuleList(self.layers)\n",
    "            self.activation = activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.linears:\n",
    "            x = self.activation(layer(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.from_numpy(scaled_x_train).float()\n",
    "# y = torch.from_numpy(y_train.values.reshape(-1, 1)).float()\n",
    "\n",
    "# inputs = Variable(x)\n",
    "# targets = Variable(y)\n",
    "\n",
    "# # base = base_model(1, [1], activation=torch.nn.Tanh())\n",
    "# base = base_model(2, [6, 3])\n",
    "# print(base)\n",
    "# optimizer = torch.optim.Adagrad(base.parameters(), lr=0.2)\n",
    "# loss_func = torch.nn.MSELoss()\n",
    "\n",
    "# for i in range(100000):\n",
    "#    prediction = base(inputs)\n",
    "#    loss = loss_func(prediction, targets)\n",
    "#    if i % 100 == 0:\n",
    "#       print(loss)\n",
    "#    optimizer.zero_grad()\n",
    "#    loss.backward()\n",
    "#    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Used TanH instead of ReLU\n",
    "- Adagrad instead of SGD -> SGD just returned 0 for all predictions\n",
    "- More layers -> more overfitting, run simpler networks for more epochs gets better test error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series(prediction.detach().numpy().reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sqrt(loss.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_x = Variable(torch.from_numpy(scaled_x_test).float())\n",
    "# test_y = Variable(torch.from_numpy(y_test.values.reshape(-1, 1)).float())\n",
    "# test_predictions = base(test_x)\n",
    "# valid_x = Variable(torch.from_numpy(scaled_x_valid).float())\n",
    "# valid_y = Variable(torch.from_numpy(y_valid.values.reshape(-1, 1)).float())\n",
    "# valid_predictions = base(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = loss_func(valid_predictions, valid_y)\n",
    "# print(np.sqrt(loss.detach().numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "\n",
    "    # 2. Suggest values of the hyperparameters using a trial object.\n",
    "    n_layers = trial.suggest_int('n_layers', 0, 3)\n",
    "    n_hidden_units = [0] * n_layers\n",
    "    print(n_layers)\n",
    "    for i in range(n_layers):\n",
    "        n_hidden_units[i] = trial.suggest_int(f\"n_h_{i}\", 1, 100)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 5e-1, log=True)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 1000, 100000)\n",
    "    print(f\"\"\"Params:\n",
    "          n_layers: {n_layers}\n",
    "          n_hidden_units: {n_hidden_units}\n",
    "          lr: {lr}\n",
    "          n_epochs: {n_epochs}\"\"\")\n",
    "        \n",
    "    x = torch.from_numpy(scaled_x_train).float()\n",
    "    y = torch.from_numpy(y_train.values.reshape(-1, 1)).float()\n",
    "\n",
    "    inputs = Variable(x)\n",
    "    targets = Variable(y)\n",
    "\n",
    "    # base = base_model(1, [1], activation=torch.nn.Tanh())\n",
    "    base = base_model(n_layers, n_hidden_units)\n",
    "    optimizer = torch.optim.Adagrad(base.parameters(), lr=lr)\n",
    "    loss_func = torch.nn.MSELoss()\n",
    "\n",
    "    for i in range(n_epochs):\n",
    "        prediction = base(inputs)\n",
    "        loss = loss_func(prediction, targets)\n",
    "        if i % 1000 == 0:\n",
    "            print(loss)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "    valid_x = Variable(torch.from_numpy(scaled_x_valid).float())\n",
    "    valid_y = Variable(torch.from_numpy(y_valid.values.reshape(-1, 1)).float())\n",
    "    valid_predictions = base(valid_x)\n",
    "    loss = loss_func(valid_predictions, valid_y)\n",
    "    print(f\"Final valid loss: {loss}\")\n",
    "    print(\"#################\")\n",
    "    return np.sqrt(loss.detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-25 14:37:51,456]\u001b[0m A new study created in memory with name: no-name-b499b87c-2199-4190-81d6-4d240c6b8871\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Params:\n",
      "          n_layers: 3\n",
      "          n_hidden_units: [75, 85, 75]\n",
      "          lr: 1.637924578685429e-05\n",
      "          n_epochs: 81348\n",
      "tensor(9497003., grad_fn=<MseLossBackward0>)\n",
      "tensor(9496752., grad_fn=<MseLossBackward0>)\n",
      "tensor(9496636., grad_fn=<MseLossBackward0>)\n",
      "tensor(9496543., grad_fn=<MseLossBackward0>)\n",
      "tensor(9496460., grad_fn=<MseLossBackward0>)\n",
      "tensor(9496385., grad_fn=<MseLossBackward0>)\n",
      "tensor(9496315., grad_fn=<MseLossBackward0>)\n",
      "tensor(9496247., grad_fn=<MseLossBackward0>)\n",
      "tensor(9496181., grad_fn=<MseLossBackward0>)\n",
      "tensor(9496118., grad_fn=<MseLossBackward0>)\n",
      "tensor(9496057., grad_fn=<MseLossBackward0>)\n",
      "tensor(9495995., grad_fn=<MseLossBackward0>)\n",
      "tensor(9495934., grad_fn=<MseLossBackward0>)\n",
      "tensor(9495875., grad_fn=<MseLossBackward0>)\n",
      "tensor(9495818., grad_fn=<MseLossBackward0>)\n",
      "tensor(9495760., grad_fn=<MseLossBackward0>)\n",
      "tensor(9495701., grad_fn=<MseLossBackward0>)\n",
      "tensor(9495644., grad_fn=<MseLossBackward0>)\n",
      "tensor(9495586., grad_fn=<MseLossBackward0>)\n",
      "tensor(9495529., grad_fn=<MseLossBackward0>)\n",
      "tensor(9495471., grad_fn=<MseLossBackward0>)\n",
      "tensor(9495414., grad_fn=<MseLossBackward0>)\n",
      "tensor(9495357., grad_fn=<MseLossBackward0>)\n",
      "tensor(9495300., grad_fn=<MseLossBackward0>)\n",
      "tensor(9495242., grad_fn=<MseLossBackward0>)\n",
      "tensor(9495184., grad_fn=<MseLossBackward0>)\n",
      "tensor(9495127., grad_fn=<MseLossBackward0>)\n",
      "tensor(9495069., grad_fn=<MseLossBackward0>)\n",
      "tensor(9495011., grad_fn=<MseLossBackward0>)\n",
      "tensor(9494954., grad_fn=<MseLossBackward0>)\n",
      "tensor(9494896., grad_fn=<MseLossBackward0>)\n",
      "tensor(9494838., grad_fn=<MseLossBackward0>)\n",
      "tensor(9494780., grad_fn=<MseLossBackward0>)\n",
      "tensor(9494720., grad_fn=<MseLossBackward0>)\n",
      "tensor(9494663., grad_fn=<MseLossBackward0>)\n",
      "tensor(9494602., grad_fn=<MseLossBackward0>)\n",
      "tensor(9494543., grad_fn=<MseLossBackward0>)\n",
      "tensor(9494483., grad_fn=<MseLossBackward0>)\n",
      "tensor(9494423., grad_fn=<MseLossBackward0>)\n",
      "tensor(9494363., grad_fn=<MseLossBackward0>)\n",
      "tensor(9494302., grad_fn=<MseLossBackward0>)\n",
      "tensor(9494242., grad_fn=<MseLossBackward0>)\n",
      "tensor(9494181., grad_fn=<MseLossBackward0>)\n",
      "tensor(9494120., grad_fn=<MseLossBackward0>)\n",
      "tensor(9494058., grad_fn=<MseLossBackward0>)\n",
      "tensor(9493996., grad_fn=<MseLossBackward0>)\n",
      "tensor(9493934., grad_fn=<MseLossBackward0>)\n",
      "tensor(9493873., grad_fn=<MseLossBackward0>)\n",
      "tensor(9493810., grad_fn=<MseLossBackward0>)\n",
      "tensor(9493747., grad_fn=<MseLossBackward0>)\n",
      "tensor(9493685., grad_fn=<MseLossBackward0>)\n",
      "tensor(9493621., grad_fn=<MseLossBackward0>)\n",
      "tensor(9493556., grad_fn=<MseLossBackward0>)\n",
      "tensor(9493493., grad_fn=<MseLossBackward0>)\n",
      "tensor(9493428., grad_fn=<MseLossBackward0>)\n",
      "tensor(9493363., grad_fn=<MseLossBackward0>)\n",
      "tensor(9493299., grad_fn=<MseLossBackward0>)\n",
      "tensor(9493234., grad_fn=<MseLossBackward0>)\n",
      "tensor(9493168., grad_fn=<MseLossBackward0>)\n",
      "tensor(9493102., grad_fn=<MseLossBackward0>)\n",
      "tensor(9493037., grad_fn=<MseLossBackward0>)\n",
      "tensor(9492970., grad_fn=<MseLossBackward0>)\n",
      "tensor(9492904., grad_fn=<MseLossBackward0>)\n",
      "tensor(9492835., grad_fn=<MseLossBackward0>)\n",
      "tensor(9492770., grad_fn=<MseLossBackward0>)\n",
      "tensor(9492701., grad_fn=<MseLossBackward0>)\n",
      "tensor(9492632., grad_fn=<MseLossBackward0>)\n",
      "tensor(9492565., grad_fn=<MseLossBackward0>)\n",
      "tensor(9492496., grad_fn=<MseLossBackward0>)\n",
      "tensor(9492427., grad_fn=<MseLossBackward0>)\n",
      "tensor(9492358., grad_fn=<MseLossBackward0>)\n",
      "tensor(9492288., grad_fn=<MseLossBackward0>)\n",
      "tensor(9492218., grad_fn=<MseLossBackward0>)\n",
      "tensor(9492148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9492078., grad_fn=<MseLossBackward0>)\n",
      "tensor(9492007., grad_fn=<MseLossBackward0>)\n",
      "tensor(9491935., grad_fn=<MseLossBackward0>)\n",
      "tensor(9491864., grad_fn=<MseLossBackward0>)\n",
      "tensor(9491794., grad_fn=<MseLossBackward0>)\n",
      "tensor(9491720., grad_fn=<MseLossBackward0>)\n",
      "tensor(9491648., grad_fn=<MseLossBackward0>)\n",
      "tensor(9491576., grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-25 14:39:03,927]\u001b[0m Trial 0 finished with value: 3056.619873046875 and parameters: {'n_layers': 3, 'n_h_0': 75, 'n_h_1': 85, 'n_h_2': 75, 'lr': 1.637924578685429e-05, 'n_epochs': 81348}. Best is trial 0 with value: 3056.619873046875.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final valid loss: 9342925.0\n",
      "#################\n",
      "0\n",
      "Params:\n",
      "          n_layers: 0\n",
      "          n_hidden_units: []\n",
      "          lr: 0.03193453545811293\n",
      "          n_epochs: 97086\n",
      "tensor(9496054., grad_fn=<MseLossBackward0>)\n",
      "tensor(9446492., grad_fn=<MseLossBackward0>)\n",
      "tensor(9425732., grad_fn=<MseLossBackward0>)\n",
      "tensor(9409883., grad_fn=<MseLossBackward0>)\n",
      "tensor(9396577., grad_fn=<MseLossBackward0>)\n",
      "tensor(9384892., grad_fn=<MseLossBackward0>)\n",
      "tensor(9374359., grad_fn=<MseLossBackward0>)\n",
      "tensor(9364698., grad_fn=<MseLossBackward0>)\n",
      "tensor(9355729., grad_fn=<MseLossBackward0>)\n",
      "tensor(9347324., grad_fn=<MseLossBackward0>)\n",
      "tensor(9339393., grad_fn=<MseLossBackward0>)\n",
      "tensor(9331864., grad_fn=<MseLossBackward0>)\n",
      "tensor(9324683., grad_fn=<MseLossBackward0>)\n",
      "tensor(9317810., grad_fn=<MseLossBackward0>)\n",
      "tensor(9311208., grad_fn=<MseLossBackward0>)\n",
      "tensor(9304850., grad_fn=<MseLossBackward0>)\n",
      "tensor(9298710., grad_fn=<MseLossBackward0>)\n",
      "tensor(9292769., grad_fn=<MseLossBackward0>)\n",
      "tensor(9287009., grad_fn=<MseLossBackward0>)\n",
      "tensor(9281417., grad_fn=<MseLossBackward0>)\n",
      "tensor(9275977., grad_fn=<MseLossBackward0>)\n",
      "tensor(9270680., grad_fn=<MseLossBackward0>)\n",
      "tensor(9265516., grad_fn=<MseLossBackward0>)\n",
      "tensor(9260473., grad_fn=<MseLossBackward0>)\n",
      "tensor(9255546., grad_fn=<MseLossBackward0>)\n",
      "tensor(9250728., grad_fn=<MseLossBackward0>)\n",
      "tensor(9246011., grad_fn=<MseLossBackward0>)\n",
      "tensor(9241390., grad_fn=<MseLossBackward0>)\n",
      "tensor(9236858., grad_fn=<MseLossBackward0>)\n",
      "tensor(9232414., grad_fn=<MseLossBackward0>)\n",
      "tensor(9228051., grad_fn=<MseLossBackward0>)\n",
      "tensor(9223764., grad_fn=<MseLossBackward0>)\n",
      "tensor(9219551., grad_fn=<MseLossBackward0>)\n",
      "tensor(9215409., grad_fn=<MseLossBackward0>)\n",
      "tensor(9211334., grad_fn=<MseLossBackward0>)\n",
      "tensor(9207322., grad_fn=<MseLossBackward0>)\n",
      "tensor(9203372., grad_fn=<MseLossBackward0>)\n",
      "tensor(9199480., grad_fn=<MseLossBackward0>)\n",
      "tensor(9195646., grad_fn=<MseLossBackward0>)\n",
      "tensor(9191864., grad_fn=<MseLossBackward0>)\n",
      "tensor(9188137., grad_fn=<MseLossBackward0>)\n",
      "tensor(9184457., grad_fn=<MseLossBackward0>)\n",
      "tensor(9180827., grad_fn=<MseLossBackward0>)\n",
      "tensor(9177243., grad_fn=<MseLossBackward0>)\n",
      "tensor(9173705., grad_fn=<MseLossBackward0>)\n",
      "tensor(9170209., grad_fn=<MseLossBackward0>)\n",
      "tensor(9166757., grad_fn=<MseLossBackward0>)\n",
      "tensor(9163343., grad_fn=<MseLossBackward0>)\n",
      "tensor(9159970., grad_fn=<MseLossBackward0>)\n",
      "tensor(9156636., grad_fn=<MseLossBackward0>)\n",
      "tensor(9153337., grad_fn=<MseLossBackward0>)\n",
      "tensor(9150074., grad_fn=<MseLossBackward0>)\n",
      "tensor(9146848., grad_fn=<MseLossBackward0>)\n",
      "tensor(9143655., grad_fn=<MseLossBackward0>)\n",
      "tensor(9140494., grad_fn=<MseLossBackward0>)\n",
      "tensor(9137365., grad_fn=<MseLossBackward0>)\n",
      "tensor(9134267., grad_fn=<MseLossBackward0>)\n",
      "tensor(9131200., grad_fn=<MseLossBackward0>)\n",
      "tensor(9128163., grad_fn=<MseLossBackward0>)\n",
      "tensor(9125153., grad_fn=<MseLossBackward0>)\n",
      "tensor(9122170., grad_fn=<MseLossBackward0>)\n",
      "tensor(9119217., grad_fn=<MseLossBackward0>)\n",
      "tensor(9116290., grad_fn=<MseLossBackward0>)\n",
      "tensor(9113388., grad_fn=<MseLossBackward0>)\n",
      "tensor(9110512., grad_fn=<MseLossBackward0>)\n",
      "tensor(9107661., grad_fn=<MseLossBackward0>)\n",
      "tensor(9104833., grad_fn=<MseLossBackward0>)\n",
      "tensor(9102032., grad_fn=<MseLossBackward0>)\n",
      "tensor(9099249., grad_fn=<MseLossBackward0>)\n",
      "tensor(9096494., grad_fn=<MseLossBackward0>)\n",
      "tensor(9093754., grad_fn=<MseLossBackward0>)\n",
      "tensor(9091043., grad_fn=<MseLossBackward0>)\n",
      "tensor(9088347., grad_fn=<MseLossBackward0>)\n",
      "tensor(9085676., grad_fn=<MseLossBackward0>)\n",
      "tensor(9083024., grad_fn=<MseLossBackward0>)\n",
      "tensor(9080390., grad_fn=<MseLossBackward0>)\n",
      "tensor(9077777., grad_fn=<MseLossBackward0>)\n",
      "tensor(9075183., grad_fn=<MseLossBackward0>)\n",
      "tensor(9072607., grad_fn=<MseLossBackward0>)\n",
      "tensor(9070052., grad_fn=<MseLossBackward0>)\n",
      "tensor(9067511., grad_fn=<MseLossBackward0>)\n",
      "tensor(9064989., grad_fn=<MseLossBackward0>)\n",
      "tensor(9062487., grad_fn=<MseLossBackward0>)\n",
      "tensor(9059997., grad_fn=<MseLossBackward0>)\n",
      "tensor(9057528., grad_fn=<MseLossBackward0>)\n",
      "tensor(9055076., grad_fn=<MseLossBackward0>)\n",
      "tensor(9052634., grad_fn=<MseLossBackward0>)\n",
      "tensor(9050215., grad_fn=<MseLossBackward0>)\n",
      "tensor(9047810., grad_fn=<MseLossBackward0>)\n",
      "tensor(9045416., grad_fn=<MseLossBackward0>)\n",
      "tensor(9043040., grad_fn=<MseLossBackward0>)\n",
      "tensor(9040682., grad_fn=<MseLossBackward0>)\n",
      "tensor(9038333., grad_fn=<MseLossBackward0>)\n",
      "tensor(9036000., grad_fn=<MseLossBackward0>)\n",
      "tensor(9033685., grad_fn=<MseLossBackward0>)\n",
      "tensor(9031377., grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-25 14:39:11,382]\u001b[0m Trial 1 finished with value: 2975.86279296875 and parameters: {'n_layers': 0, 'lr': 0.03193453545811293, 'n_epochs': 97086}. Best is trial 1 with value: 2975.86279296875.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9029086., grad_fn=<MseLossBackward0>)\n",
      "tensor(9026810., grad_fn=<MseLossBackward0>)\n",
      "Final valid loss: 8855760.0\n",
      "#################\n",
      "1\n",
      "Params:\n",
      "          n_layers: 1\n",
      "          n_hidden_units: [16]\n",
      "          lr: 0.004665052206171935\n",
      "          n_epochs: 75289\n",
      "tensor(9497147., grad_fn=<MseLossBackward0>)\n",
      "tensor(9444583., grad_fn=<MseLossBackward0>)\n",
      "tensor(9386754., grad_fn=<MseLossBackward0>)\n",
      "tensor(9325733., grad_fn=<MseLossBackward0>)\n",
      "tensor(9265119., grad_fn=<MseLossBackward0>)\n",
      "tensor(9205007., grad_fn=<MseLossBackward0>)\n",
      "tensor(9145410., grad_fn=<MseLossBackward0>)\n",
      "tensor(9086318., grad_fn=<MseLossBackward0>)\n",
      "tensor(9027710., grad_fn=<MseLossBackward0>)\n",
      "tensor(8969576., grad_fn=<MseLossBackward0>)\n",
      "tensor(8911910., grad_fn=<MseLossBackward0>)\n",
      "tensor(8854711., grad_fn=<MseLossBackward0>)\n",
      "tensor(8797959., grad_fn=<MseLossBackward0>)\n",
      "tensor(8741659., grad_fn=<MseLossBackward0>)\n",
      "tensor(8685791., grad_fn=<MseLossBackward0>)\n",
      "tensor(8630342., grad_fn=<MseLossBackward0>)\n",
      "tensor(8575297., grad_fn=<MseLossBackward0>)\n",
      "tensor(8520634., grad_fn=<MseLossBackward0>)\n",
      "tensor(8466382., grad_fn=<MseLossBackward0>)\n",
      "tensor(8412543., grad_fn=<MseLossBackward0>)\n",
      "tensor(8359105., grad_fn=<MseLossBackward0>)\n",
      "tensor(8306052., grad_fn=<MseLossBackward0>)\n",
      "tensor(8253418., grad_fn=<MseLossBackward0>)\n",
      "tensor(8201208.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(8149422.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(8098061., grad_fn=<MseLossBackward0>)\n",
      "tensor(8047113., grad_fn=<MseLossBackward0>)\n",
      "tensor(7996554.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(7946396.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(7896642., grad_fn=<MseLossBackward0>)\n",
      "tensor(7847288., grad_fn=<MseLossBackward0>)\n",
      "tensor(7798327.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(7749768., grad_fn=<MseLossBackward0>)\n",
      "tensor(7701599.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(7653819.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(7606427., grad_fn=<MseLossBackward0>)\n",
      "tensor(7559419., grad_fn=<MseLossBackward0>)\n",
      "tensor(7512791., grad_fn=<MseLossBackward0>)\n",
      "tensor(7466545., grad_fn=<MseLossBackward0>)\n",
      "tensor(7420672., grad_fn=<MseLossBackward0>)\n",
      "tensor(7375170., grad_fn=<MseLossBackward0>)\n",
      "tensor(7330036., grad_fn=<MseLossBackward0>)\n",
      "tensor(7285274., grad_fn=<MseLossBackward0>)\n",
      "tensor(7240873., grad_fn=<MseLossBackward0>)\n",
      "tensor(7196831., grad_fn=<MseLossBackward0>)\n",
      "tensor(7153149.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(7109819.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(7066850., grad_fn=<MseLossBackward0>)\n",
      "tensor(7024233., grad_fn=<MseLossBackward0>)\n",
      "tensor(6981968.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(6940045., grad_fn=<MseLossBackward0>)\n",
      "tensor(6898469.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(6857226., grad_fn=<MseLossBackward0>)\n",
      "tensor(6816325.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(6775765., grad_fn=<MseLossBackward0>)\n",
      "tensor(6735542., grad_fn=<MseLossBackward0>)\n",
      "tensor(6695648., grad_fn=<MseLossBackward0>)\n",
      "tensor(6656085.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(6616856., grad_fn=<MseLossBackward0>)\n",
      "tensor(6577953.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(6539371., grad_fn=<MseLossBackward0>)\n",
      "tensor(6501106., grad_fn=<MseLossBackward0>)\n",
      "tensor(6463159.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(6425530.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(6388213.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(6351204., grad_fn=<MseLossBackward0>)\n",
      "tensor(6314509., grad_fn=<MseLossBackward0>)\n",
      "tensor(6278120., grad_fn=<MseLossBackward0>)\n",
      "tensor(6242029., grad_fn=<MseLossBackward0>)\n",
      "tensor(6206236., grad_fn=<MseLossBackward0>)\n",
      "tensor(6170744.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(6135549.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(6100640., grad_fn=<MseLossBackward0>)\n",
      "tensor(6066022., grad_fn=<MseLossBackward0>)\n",
      "tensor(6031703.5000, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-25 14:39:22,226]\u001b[0m Trial 2 finished with value: 2417.63134765625 and parameters: {'n_layers': 1, 'n_h_0': 16, 'lr': 0.004665052206171935, 'n_epochs': 75289}. Best is trial 2 with value: 2417.63134765625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5997677.5000, grad_fn=<MseLossBackward0>)\n",
      "Final valid loss: 5844941.5\n",
      "#################\n",
      "2\n",
      "Params:\n",
      "          n_layers: 2\n",
      "          n_hidden_units: [3, 54]\n",
      "          lr: 0.0037085756817440765\n",
      "          n_epochs: 22655\n",
      "tensor(9497132., grad_fn=<MseLossBackward0>)\n",
      "tensor(9319807., grad_fn=<MseLossBackward0>)\n",
      "tensor(8981219., grad_fn=<MseLossBackward0>)\n",
      "tensor(8554631., grad_fn=<MseLossBackward0>)\n",
      "tensor(8081075.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(7585001., grad_fn=<MseLossBackward0>)\n",
      "tensor(7085138.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(6590692.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(6109843., grad_fn=<MseLossBackward0>)\n",
      "tensor(5650161.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(5225003.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(4835146., grad_fn=<MseLossBackward0>)\n",
      "tensor(4481948., grad_fn=<MseLossBackward0>)\n",
      "tensor(4167104.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(3891951., grad_fn=<MseLossBackward0>)\n",
      "tensor(3652882., grad_fn=<MseLossBackward0>)\n",
      "tensor(3446578.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(3268991.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(3116182.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(2984510.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(2871417., grad_fn=<MseLossBackward0>)\n",
      "tensor(2774132., grad_fn=<MseLossBackward0>)\n",
      "tensor(2689543.2500, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-25 14:39:30,557]\u001b[0m Trial 3 finished with value: 1674.7156982421875 and parameters: {'n_layers': 2, 'n_h_0': 3, 'n_h_1': 54, 'lr': 0.0037085756817440765, 'n_epochs': 22655}. Best is trial 3 with value: 1674.7156982421875.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final valid loss: 2804672.5\n",
      "#################\n",
      "2\n",
      "Params:\n",
      "          n_layers: 2\n",
      "          n_hidden_units: [79, 57]\n",
      "          lr: 6.021243073181496e-05\n",
      "          n_epochs: 46471\n",
      "tensor(9497134., grad_fn=<MseLossBackward0>)\n",
      "tensor(9496372., grad_fn=<MseLossBackward0>)\n",
      "tensor(9495890., grad_fn=<MseLossBackward0>)\n",
      "tensor(9495501., grad_fn=<MseLossBackward0>)\n",
      "tensor(9495153., grad_fn=<MseLossBackward0>)\n",
      "tensor(9494830., grad_fn=<MseLossBackward0>)\n",
      "tensor(9494521., grad_fn=<MseLossBackward0>)\n",
      "tensor(9494225., grad_fn=<MseLossBackward0>)\n",
      "tensor(9493933., grad_fn=<MseLossBackward0>)\n",
      "tensor(9493647., grad_fn=<MseLossBackward0>)\n",
      "tensor(9493365., grad_fn=<MseLossBackward0>)\n",
      "tensor(9493084., grad_fn=<MseLossBackward0>)\n",
      "tensor(9492806., grad_fn=<MseLossBackward0>)\n",
      "tensor(9492531., grad_fn=<MseLossBackward0>)\n",
      "tensor(9492256., grad_fn=<MseLossBackward0>)\n",
      "tensor(9491981., grad_fn=<MseLossBackward0>)\n",
      "tensor(9491708., grad_fn=<MseLossBackward0>)\n",
      "tensor(9491435., grad_fn=<MseLossBackward0>)\n",
      "tensor(9491162., grad_fn=<MseLossBackward0>)\n",
      "tensor(9490890., grad_fn=<MseLossBackward0>)\n",
      "tensor(9490618., grad_fn=<MseLossBackward0>)\n",
      "tensor(9490348., grad_fn=<MseLossBackward0>)\n",
      "tensor(9490076., grad_fn=<MseLossBackward0>)\n",
      "tensor(9489806., grad_fn=<MseLossBackward0>)\n",
      "tensor(9489534., grad_fn=<MseLossBackward0>)\n",
      "tensor(9489262., grad_fn=<MseLossBackward0>)\n",
      "tensor(9488991., grad_fn=<MseLossBackward0>)\n",
      "tensor(9488720., grad_fn=<MseLossBackward0>)\n",
      "tensor(9488447., grad_fn=<MseLossBackward0>)\n",
      "tensor(9488173., grad_fn=<MseLossBackward0>)\n",
      "tensor(9487900., grad_fn=<MseLossBackward0>)\n",
      "tensor(9487624., grad_fn=<MseLossBackward0>)\n",
      "tensor(9487349., grad_fn=<MseLossBackward0>)\n",
      "tensor(9487072., grad_fn=<MseLossBackward0>)\n",
      "tensor(9486793., grad_fn=<MseLossBackward0>)\n",
      "tensor(9486515., grad_fn=<MseLossBackward0>)\n",
      "tensor(9486235., grad_fn=<MseLossBackward0>)\n",
      "tensor(9485956., grad_fn=<MseLossBackward0>)\n",
      "tensor(9485675., grad_fn=<MseLossBackward0>)\n",
      "tensor(9485394., grad_fn=<MseLossBackward0>)\n",
      "tensor(9485111., grad_fn=<MseLossBackward0>)\n",
      "tensor(9484827., grad_fn=<MseLossBackward0>)\n",
      "tensor(9484543., grad_fn=<MseLossBackward0>)\n",
      "tensor(9484259., grad_fn=<MseLossBackward0>)\n",
      "tensor(9483971., grad_fn=<MseLossBackward0>)\n",
      "tensor(9483684., grad_fn=<MseLossBackward0>)\n",
      "tensor(9483397., grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-25 14:39:56,559]\u001b[0m Trial 4 finished with value: 3055.2568359375 and parameters: {'n_layers': 2, 'n_h_0': 79, 'n_h_1': 57, 'lr': 6.021243073181496e-05, 'n_epochs': 46471}. Best is trial 3 with value: 1674.7156982421875.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final valid loss: 9334594.0\n",
      "#################\n",
      "2\n",
      "Params:\n",
      "          n_layers: 2\n",
      "          n_hidden_units: [51, 23]\n",
      "          lr: 7.038211240965335e-05\n",
      "          n_epochs: 68086\n",
      "tensor(9497125., grad_fn=<MseLossBackward0>)\n",
      "tensor(9496886., grad_fn=<MseLossBackward0>)\n",
      "tensor(9496547., grad_fn=<MseLossBackward0>)\n",
      "tensor(9496245., grad_fn=<MseLossBackward0>)\n",
      "tensor(9495970., grad_fn=<MseLossBackward0>)\n",
      "tensor(9495709., grad_fn=<MseLossBackward0>)\n",
      "tensor(9495462., grad_fn=<MseLossBackward0>)\n",
      "tensor(9495231., grad_fn=<MseLossBackward0>)\n",
      "tensor(9495009., grad_fn=<MseLossBackward0>)\n",
      "tensor(9494795., grad_fn=<MseLossBackward0>)\n",
      "tensor(9494588., grad_fn=<MseLossBackward0>)\n",
      "tensor(9494385., grad_fn=<MseLossBackward0>)\n",
      "tensor(9494189., grad_fn=<MseLossBackward0>)\n",
      "tensor(9493995., grad_fn=<MseLossBackward0>)\n",
      "tensor(9493804., grad_fn=<MseLossBackward0>)\n",
      "tensor(9493615., grad_fn=<MseLossBackward0>)\n",
      "tensor(9493429., grad_fn=<MseLossBackward0>)\n",
      "tensor(9493246., grad_fn=<MseLossBackward0>)\n",
      "tensor(9493062., grad_fn=<MseLossBackward0>)\n",
      "tensor(9492881., grad_fn=<MseLossBackward0>)\n",
      "tensor(9492702., grad_fn=<MseLossBackward0>)\n",
      "tensor(9492523., grad_fn=<MseLossBackward0>)\n",
      "tensor(9492344., grad_fn=<MseLossBackward0>)\n",
      "tensor(9492169., grad_fn=<MseLossBackward0>)\n",
      "tensor(9491992., grad_fn=<MseLossBackward0>)\n",
      "tensor(9491817., grad_fn=<MseLossBackward0>)\n",
      "tensor(9491641., grad_fn=<MseLossBackward0>)\n",
      "tensor(9491468., grad_fn=<MseLossBackward0>)\n",
      "tensor(9491295., grad_fn=<MseLossBackward0>)\n",
      "tensor(9491120., grad_fn=<MseLossBackward0>)\n",
      "tensor(9490947., grad_fn=<MseLossBackward0>)\n",
      "tensor(9490774., grad_fn=<MseLossBackward0>)\n",
      "tensor(9490602., grad_fn=<MseLossBackward0>)\n",
      "tensor(9490430., grad_fn=<MseLossBackward0>)\n",
      "tensor(9490258., grad_fn=<MseLossBackward0>)\n",
      "tensor(9490085., grad_fn=<MseLossBackward0>)\n",
      "tensor(9489915., grad_fn=<MseLossBackward0>)\n",
      "tensor(9489742., grad_fn=<MseLossBackward0>)\n",
      "tensor(9489569., grad_fn=<MseLossBackward0>)\n",
      "tensor(9489398., grad_fn=<MseLossBackward0>)\n",
      "tensor(9489226., grad_fn=<MseLossBackward0>)\n",
      "tensor(9489054., grad_fn=<MseLossBackward0>)\n",
      "tensor(9488881., grad_fn=<MseLossBackward0>)\n",
      "tensor(9488710., grad_fn=<MseLossBackward0>)\n",
      "tensor(9488537., grad_fn=<MseLossBackward0>)\n",
      "tensor(9488364., grad_fn=<MseLossBackward0>)\n",
      "tensor(9488192., grad_fn=<MseLossBackward0>)\n",
      "tensor(9488020., grad_fn=<MseLossBackward0>)\n",
      "tensor(9487847., grad_fn=<MseLossBackward0>)\n",
      "tensor(9487673., grad_fn=<MseLossBackward0>)\n",
      "tensor(9487499., grad_fn=<MseLossBackward0>)\n",
      "tensor(9487326., grad_fn=<MseLossBackward0>)\n",
      "tensor(9487151., grad_fn=<MseLossBackward0>)\n",
      "tensor(9486978., grad_fn=<MseLossBackward0>)\n",
      "tensor(9486802., grad_fn=<MseLossBackward0>)\n",
      "tensor(9486628., grad_fn=<MseLossBackward0>)\n",
      "tensor(9486452., grad_fn=<MseLossBackward0>)\n",
      "tensor(9486277., grad_fn=<MseLossBackward0>)\n",
      "tensor(9486100., grad_fn=<MseLossBackward0>)\n",
      "tensor(9485924., grad_fn=<MseLossBackward0>)\n",
      "tensor(9485747., grad_fn=<MseLossBackward0>)\n",
      "tensor(9485570., grad_fn=<MseLossBackward0>)\n",
      "tensor(9485392., grad_fn=<MseLossBackward0>)\n",
      "tensor(9485215., grad_fn=<MseLossBackward0>)\n",
      "tensor(9485036., grad_fn=<MseLossBackward0>)\n",
      "tensor(9484856., grad_fn=<MseLossBackward0>)\n",
      "tensor(9484677., grad_fn=<MseLossBackward0>)\n",
      "tensor(9484497., grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-25 14:40:22,157]\u001b[0m Trial 5 finished with value: 3055.42626953125 and parameters: {'n_layers': 2, 'n_h_0': 51, 'n_h_1': 23, 'lr': 7.038211240965335e-05, 'n_epochs': 68086}. Best is trial 3 with value: 1674.7156982421875.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9484317., grad_fn=<MseLossBackward0>)\n",
      "Final valid loss: 9335629.0\n",
      "#################\n",
      "1\n",
      "Params:\n",
      "          n_layers: 1\n",
      "          n_hidden_units: [60]\n",
      "          lr: 0.00018927773057705275\n",
      "          n_epochs: 15882\n",
      "tensor(9496569., grad_fn=<MseLossBackward0>)\n",
      "tensor(9495174., grad_fn=<MseLossBackward0>)\n",
      "tensor(9494464., grad_fn=<MseLossBackward0>)\n",
      "tensor(9493867., grad_fn=<MseLossBackward0>)\n",
      "tensor(9493317., grad_fn=<MseLossBackward0>)\n",
      "tensor(9492814., grad_fn=<MseLossBackward0>)\n",
      "tensor(9492348., grad_fn=<MseLossBackward0>)\n",
      "tensor(9491914., grad_fn=<MseLossBackward0>)\n",
      "tensor(9491501., grad_fn=<MseLossBackward0>)\n",
      "tensor(9491105., grad_fn=<MseLossBackward0>)\n",
      "tensor(9490722., grad_fn=<MseLossBackward0>)\n",
      "tensor(9490353., grad_fn=<MseLossBackward0>)\n",
      "tensor(9489993., grad_fn=<MseLossBackward0>)\n",
      "tensor(9489638., grad_fn=<MseLossBackward0>)\n",
      "tensor(9489291., grad_fn=<MseLossBackward0>)\n",
      "tensor(9488948., grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-25 14:40:26,629]\u001b[0m Trial 6 finished with value: 3056.16943359375 and parameters: {'n_layers': 1, 'n_h_0': 60, 'lr': 0.00018927773057705275, 'n_epochs': 15882}. Best is trial 3 with value: 1674.7156982421875.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final valid loss: 9340171.0\n",
      "#################\n",
      "3\n",
      "Params:\n",
      "          n_layers: 3\n",
      "          n_hidden_units: [55, 62, 62]\n",
      "          lr: 0.006581640845845318\n",
      "          n_epochs: 63722\n",
      "tensor(9496508., grad_fn=<MseLossBackward0>)\n",
      "tensor(1020378., grad_fn=<MseLossBackward0>)\n",
      "tensor(885837.8750, grad_fn=<MseLossBackward0>)\n",
      "tensor(820588.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(776168.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(744366.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(719408.9375, grad_fn=<MseLossBackward0>)\n",
      "tensor(698061.6250, grad_fn=<MseLossBackward0>)\n",
      "tensor(679130.1875, grad_fn=<MseLossBackward0>)\n",
      "tensor(661247.1875, grad_fn=<MseLossBackward0>)\n",
      "tensor(644418.5625, grad_fn=<MseLossBackward0>)\n",
      "tensor(628135.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(612661.8125, grad_fn=<MseLossBackward0>)\n",
      "tensor(598861.6250, grad_fn=<MseLossBackward0>)\n",
      "tensor(585950.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(574102.1875, grad_fn=<MseLossBackward0>)\n",
      "tensor(563015.5625, grad_fn=<MseLossBackward0>)\n",
      "tensor(552119.1875, grad_fn=<MseLossBackward0>)\n",
      "tensor(541983.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(532553.8125, grad_fn=<MseLossBackward0>)\n",
      "tensor(522779.4062, grad_fn=<MseLossBackward0>)\n",
      "tensor(513065.8438, grad_fn=<MseLossBackward0>)\n",
      "tensor(503952.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(495059.6562, grad_fn=<MseLossBackward0>)\n",
      "tensor(486537.5938, grad_fn=<MseLossBackward0>)\n",
      "tensor(478543.9375, grad_fn=<MseLossBackward0>)\n",
      "tensor(471023.5312, grad_fn=<MseLossBackward0>)\n",
      "tensor(463632.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(455963.0625, grad_fn=<MseLossBackward0>)\n",
      "tensor(448275.4688, grad_fn=<MseLossBackward0>)\n",
      "tensor(439980.2188, grad_fn=<MseLossBackward0>)\n",
      "tensor(430887.5938, grad_fn=<MseLossBackward0>)\n",
      "tensor(421498.3125, grad_fn=<MseLossBackward0>)\n",
      "tensor(412487.3750, grad_fn=<MseLossBackward0>)\n",
      "tensor(404285.4688, grad_fn=<MseLossBackward0>)\n",
      "tensor(396861.5938, grad_fn=<MseLossBackward0>)\n",
      "tensor(389679.0625, grad_fn=<MseLossBackward0>)\n",
      "tensor(383032.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(376327.5312, grad_fn=<MseLossBackward0>)\n",
      "tensor(369756.3438, grad_fn=<MseLossBackward0>)\n",
      "tensor(363672.2812, grad_fn=<MseLossBackward0>)\n",
      "tensor(357596.0625, grad_fn=<MseLossBackward0>)\n",
      "tensor(351291.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor(345525.4062, grad_fn=<MseLossBackward0>)\n",
      "tensor(339535.6875, grad_fn=<MseLossBackward0>)\n",
      "tensor(333550.1250, grad_fn=<MseLossBackward0>)\n",
      "tensor(327559.4688, grad_fn=<MseLossBackward0>)\n",
      "tensor(321619.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(315700.8438, grad_fn=<MseLossBackward0>)\n",
      "tensor(310041.7188, grad_fn=<MseLossBackward0>)\n",
      "tensor(304639.7812, grad_fn=<MseLossBackward0>)\n",
      "tensor(299351.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor(293825.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor(287729.4375, grad_fn=<MseLossBackward0>)\n",
      "tensor(282060.1562, grad_fn=<MseLossBackward0>)\n",
      "tensor(276662.0938, grad_fn=<MseLossBackward0>)\n",
      "tensor(271271.3438, grad_fn=<MseLossBackward0>)\n",
      "tensor(266023.5312, grad_fn=<MseLossBackward0>)\n",
      "tensor(260707.1406, grad_fn=<MseLossBackward0>)\n",
      "tensor(255967.6250, grad_fn=<MseLossBackward0>)\n",
      "tensor(251312.0469, grad_fn=<MseLossBackward0>)\n",
      "tensor(246928.2812, grad_fn=<MseLossBackward0>)\n",
      "tensor(242576.9219, grad_fn=<MseLossBackward0>)\n",
      "tensor(238361.7812, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-25 14:41:14,970]\u001b[0m Trial 7 finished with value: 908.2461547851562 and parameters: {'n_layers': 3, 'n_h_0': 55, 'n_h_1': 62, 'n_h_2': 62, 'lr': 0.006581640845845318, 'n_epochs': 63722}. Best is trial 7 with value: 908.2461547851562.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final valid loss: 824911.0625\n",
      "#################\n",
      "2\n",
      "Params:\n",
      "          n_layers: 2\n",
      "          n_hidden_units: [10, 84]\n",
      "          lr: 1.5264029860954243e-05\n",
      "          n_epochs: 33208\n",
      "tensor(9497147., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497143., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497137., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497132., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497126., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497119., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497111., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497104., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497095., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497084., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497073., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497060., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497044., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497028., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497011., grad_fn=<MseLossBackward0>)\n",
      "tensor(9496993., grad_fn=<MseLossBackward0>)\n",
      "tensor(9496973., grad_fn=<MseLossBackward0>)\n",
      "tensor(9496953., grad_fn=<MseLossBackward0>)\n",
      "tensor(9496931., grad_fn=<MseLossBackward0>)\n",
      "tensor(9496910., grad_fn=<MseLossBackward0>)\n",
      "tensor(9496890., grad_fn=<MseLossBackward0>)\n",
      "tensor(9496870., grad_fn=<MseLossBackward0>)\n",
      "tensor(9496850., grad_fn=<MseLossBackward0>)\n",
      "tensor(9496830., grad_fn=<MseLossBackward0>)\n",
      "tensor(9496811., grad_fn=<MseLossBackward0>)\n",
      "tensor(9496793., grad_fn=<MseLossBackward0>)\n",
      "tensor(9496776., grad_fn=<MseLossBackward0>)\n",
      "tensor(9496758., grad_fn=<MseLossBackward0>)\n",
      "tensor(9496741., grad_fn=<MseLossBackward0>)\n",
      "tensor(9496724., grad_fn=<MseLossBackward0>)\n",
      "tensor(9496709., grad_fn=<MseLossBackward0>)\n",
      "tensor(9496693., grad_fn=<MseLossBackward0>)\n",
      "tensor(9496678., grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-25 14:41:28,799]\u001b[0m Trial 8 finished with value: 3057.467529296875 and parameters: {'n_layers': 2, 'n_h_0': 10, 'n_h_1': 84, 'lr': 1.5264029860954243e-05, 'n_epochs': 33208}. Best is trial 7 with value: 908.2461547851562.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9496662., grad_fn=<MseLossBackward0>)\n",
      "Final valid loss: 9348108.0\n",
      "#################\n",
      "2\n",
      "Params:\n",
      "          n_layers: 2\n",
      "          n_hidden_units: [90, 28]\n",
      "          lr: 0.05427120975261596\n",
      "          n_epochs: 67955\n",
      "tensor(9496990., grad_fn=<MseLossBackward0>)\n",
      "tensor(721103.1875, grad_fn=<MseLossBackward0>)\n",
      "tensor(651679.6250, grad_fn=<MseLossBackward0>)\n",
      "tensor(615077.3750, grad_fn=<MseLossBackward0>)\n",
      "tensor(547621.6250, grad_fn=<MseLossBackward0>)\n",
      "tensor(480261.5625, grad_fn=<MseLossBackward0>)\n",
      "tensor(424269.3125, grad_fn=<MseLossBackward0>)\n",
      "tensor(367163.0938, grad_fn=<MseLossBackward0>)\n",
      "tensor(319390.9688, grad_fn=<MseLossBackward0>)\n",
      "tensor(283337.8750, grad_fn=<MseLossBackward0>)\n",
      "tensor(254803.1094, grad_fn=<MseLossBackward0>)\n",
      "tensor(227973.5312, grad_fn=<MseLossBackward0>)\n",
      "tensor(205236.1562, grad_fn=<MseLossBackward0>)\n",
      "tensor(188791.6719, grad_fn=<MseLossBackward0>)\n",
      "tensor(174752., grad_fn=<MseLossBackward0>)\n",
      "tensor(163428.7344, grad_fn=<MseLossBackward0>)\n",
      "tensor(153638.7812, grad_fn=<MseLossBackward0>)\n",
      "tensor(145414.6875, grad_fn=<MseLossBackward0>)\n",
      "tensor(138410.1719, grad_fn=<MseLossBackward0>)\n",
      "tensor(131635.8750, grad_fn=<MseLossBackward0>)\n",
      "tensor(125321.9219, grad_fn=<MseLossBackward0>)\n",
      "tensor(120122.8125, grad_fn=<MseLossBackward0>)\n",
      "tensor(115350.6641, grad_fn=<MseLossBackward0>)\n",
      "tensor(111391.7578, grad_fn=<MseLossBackward0>)\n",
      "tensor(107900.2188, grad_fn=<MseLossBackward0>)\n",
      "tensor(104814.4531, grad_fn=<MseLossBackward0>)\n",
      "tensor(101904.3750, grad_fn=<MseLossBackward0>)\n",
      "tensor(98835.1875, grad_fn=<MseLossBackward0>)\n",
      "tensor(96175.9766, grad_fn=<MseLossBackward0>)\n",
      "tensor(93748.0781, grad_fn=<MseLossBackward0>)\n",
      "tensor(91595.6562, grad_fn=<MseLossBackward0>)\n",
      "tensor(89720.4922, grad_fn=<MseLossBackward0>)\n",
      "tensor(87790.6250, grad_fn=<MseLossBackward0>)\n",
      "tensor(86067.1875, grad_fn=<MseLossBackward0>)\n",
      "tensor(84339.2891, grad_fn=<MseLossBackward0>)\n",
      "tensor(82895.8203, grad_fn=<MseLossBackward0>)\n",
      "tensor(81447.8672, grad_fn=<MseLossBackward0>)\n",
      "tensor(80075.6094, grad_fn=<MseLossBackward0>)\n",
      "tensor(78690.5938, grad_fn=<MseLossBackward0>)\n",
      "tensor(77423.8438, grad_fn=<MseLossBackward0>)\n",
      "tensor(76154.3359, grad_fn=<MseLossBackward0>)\n",
      "tensor(74801.0938, grad_fn=<MseLossBackward0>)\n",
      "tensor(73565.2188, grad_fn=<MseLossBackward0>)\n",
      "tensor(72475.9141, grad_fn=<MseLossBackward0>)\n",
      "tensor(71378.8594, grad_fn=<MseLossBackward0>)\n",
      "tensor(70373.9844, grad_fn=<MseLossBackward0>)\n",
      "tensor(69256.6250, grad_fn=<MseLossBackward0>)\n",
      "tensor(68193.9141, grad_fn=<MseLossBackward0>)\n",
      "tensor(67208.6250, grad_fn=<MseLossBackward0>)\n",
      "tensor(66247.9375, grad_fn=<MseLossBackward0>)\n",
      "tensor(65232.7656, grad_fn=<MseLossBackward0>)\n",
      "tensor(64300.1992, grad_fn=<MseLossBackward0>)\n",
      "tensor(63394.6992, grad_fn=<MseLossBackward0>)\n",
      "tensor(62620.7383, grad_fn=<MseLossBackward0>)\n",
      "tensor(61843.3320, grad_fn=<MseLossBackward0>)\n",
      "tensor(61141.1914, grad_fn=<MseLossBackward0>)\n",
      "tensor(60436.3320, grad_fn=<MseLossBackward0>)\n",
      "tensor(59735.0430, grad_fn=<MseLossBackward0>)\n",
      "tensor(59053.6367, grad_fn=<MseLossBackward0>)\n",
      "tensor(58385.1133, grad_fn=<MseLossBackward0>)\n",
      "tensor(57675.8203, grad_fn=<MseLossBackward0>)\n",
      "tensor(57003.5430, grad_fn=<MseLossBackward0>)\n",
      "tensor(56277.0898, grad_fn=<MseLossBackward0>)\n",
      "tensor(55692.3203, grad_fn=<MseLossBackward0>)\n",
      "tensor(55022.4844, grad_fn=<MseLossBackward0>)\n",
      "tensor(54397.1289, grad_fn=<MseLossBackward0>)\n",
      "tensor(53673.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(52830.0625, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-25 14:42:03,337]\u001b[0m Trial 9 finished with value: 1193.8299560546875 and parameters: {'n_layers': 2, 'n_h_0': 90, 'n_h_1': 28, 'lr': 0.05427120975261596, 'n_epochs': 67955}. Best is trial 7 with value: 908.2461547851562.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final valid loss: 1425230.0\n",
      "#################\n",
      "3\n",
      "Params:\n",
      "          n_layers: 3\n",
      "          n_hidden_units: [33, 3, 22]\n",
      "          lr: 0.3739739949663906\n",
      "          n_epochs: 1072\n",
      "tensor(9496591., grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-25 14:42:03,787]\u001b[0m Trial 10 finished with value: 905.126953125 and parameters: {'n_layers': 3, 'n_h_0': 33, 'n_h_1': 3, 'n_h_2': 22, 'lr': 0.3739739949663906, 'n_epochs': 1072}. Best is trial 10 with value: 905.126953125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(565486.3125, grad_fn=<MseLossBackward0>)\n",
      "Final valid loss: 819254.75\n",
      "#################\n",
      "3\n",
      "Params:\n",
      "          n_layers: 3\n",
      "          n_hidden_units: [31, 5, 11]\n",
      "          lr: 0.4972894309648099\n",
      "          n_epochs: 5738\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-25 14:42:05,987]\u001b[0m Trial 11 finished with value: 3057.548095703125 and parameters: {'n_layers': 3, 'n_h_0': 31, 'n_h_1': 5, 'n_h_2': 11, 'lr': 0.4972894309648099, 'n_epochs': 5738}. Best is trial 10 with value: 905.126953125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final valid loss: 9348601.0\n",
      "#################\n",
      "3\n",
      "Params:\n",
      "          n_layers: 3\n",
      "          n_hidden_units: [30, 66, 36]\n",
      "          lr: 0.22383589460596637\n",
      "          n_epochs: 48487\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-25 14:42:37,362]\u001b[0m Trial 12 finished with value: 3057.548095703125 and parameters: {'n_layers': 3, 'n_h_0': 30, 'n_h_1': 66, 'n_h_2': 36, 'lr': 0.22383589460596637, 'n_epochs': 48487}. Best is trial 10 with value: 905.126953125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final valid loss: 9348601.0\n",
      "#################\n",
      "3\n",
      "Params:\n",
      "          n_layers: 3\n",
      "          n_hidden_units: [37, 36, 60]\n",
      "          lr: 0.018436813724756335\n",
      "          n_epochs: 55695\n",
      "tensor(9496651., grad_fn=<MseLossBackward0>)\n",
      "tensor(751946.1875, grad_fn=<MseLossBackward0>)\n",
      "tensor(673356., grad_fn=<MseLossBackward0>)\n",
      "tensor(631153.8750, grad_fn=<MseLossBackward0>)\n",
      "tensor(603694.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(578915.3750, grad_fn=<MseLossBackward0>)\n",
      "tensor(548667.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(509101.4062, grad_fn=<MseLossBackward0>)\n",
      "tensor(462989.0312, grad_fn=<MseLossBackward0>)\n",
      "tensor(423797.0938, grad_fn=<MseLossBackward0>)\n",
      "tensor(385250.6875, grad_fn=<MseLossBackward0>)\n",
      "tensor(353181.9375, grad_fn=<MseLossBackward0>)\n",
      "tensor(324254.4062, grad_fn=<MseLossBackward0>)\n",
      "tensor(302170.9375, grad_fn=<MseLossBackward0>)\n",
      "tensor(286339.6875, grad_fn=<MseLossBackward0>)\n",
      "tensor(273803.3438, grad_fn=<MseLossBackward0>)\n",
      "tensor(262067.4062, grad_fn=<MseLossBackward0>)\n",
      "tensor(250537.4531, grad_fn=<MseLossBackward0>)\n",
      "tensor(239606.1875, grad_fn=<MseLossBackward0>)\n",
      "tensor(231469.2188, grad_fn=<MseLossBackward0>)\n",
      "tensor(223883.7969, grad_fn=<MseLossBackward0>)\n",
      "tensor(217363.1562, grad_fn=<MseLossBackward0>)\n",
      "tensor(210819., grad_fn=<MseLossBackward0>)\n",
      "tensor(205128.4531, grad_fn=<MseLossBackward0>)\n",
      "tensor(199649.4531, grad_fn=<MseLossBackward0>)\n",
      "tensor(194449.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(189116.6406, grad_fn=<MseLossBackward0>)\n",
      "tensor(182958., grad_fn=<MseLossBackward0>)\n",
      "tensor(177476.3125, grad_fn=<MseLossBackward0>)\n",
      "tensor(171863.0312, grad_fn=<MseLossBackward0>)\n",
      "tensor(167188.8594, grad_fn=<MseLossBackward0>)\n",
      "tensor(162797.0938, grad_fn=<MseLossBackward0>)\n",
      "tensor(158510.3750, grad_fn=<MseLossBackward0>)\n",
      "tensor(154452.5781, grad_fn=<MseLossBackward0>)\n",
      "tensor(151138.1406, grad_fn=<MseLossBackward0>)\n",
      "tensor(147773.8906, grad_fn=<MseLossBackward0>)\n",
      "tensor(144487.8125, grad_fn=<MseLossBackward0>)\n",
      "tensor(141469.2344, grad_fn=<MseLossBackward0>)\n",
      "tensor(138603.9844, grad_fn=<MseLossBackward0>)\n",
      "tensor(135649.3438, grad_fn=<MseLossBackward0>)\n",
      "tensor(132818.2812, grad_fn=<MseLossBackward0>)\n",
      "tensor(129775.1875, grad_fn=<MseLossBackward0>)\n",
      "tensor(126902.7031, grad_fn=<MseLossBackward0>)\n",
      "tensor(123914.3047, grad_fn=<MseLossBackward0>)\n",
      "tensor(121099.6797, grad_fn=<MseLossBackward0>)\n",
      "tensor(118364.5859, grad_fn=<MseLossBackward0>)\n",
      "tensor(115843.3906, grad_fn=<MseLossBackward0>)\n",
      "tensor(113151.1328, grad_fn=<MseLossBackward0>)\n",
      "tensor(110596.1250, grad_fn=<MseLossBackward0>)\n",
      "tensor(108057.8984, grad_fn=<MseLossBackward0>)\n",
      "tensor(105591.1719, grad_fn=<MseLossBackward0>)\n",
      "tensor(102975.1172, grad_fn=<MseLossBackward0>)\n",
      "tensor(100514.1875, grad_fn=<MseLossBackward0>)\n",
      "tensor(98433.8828, grad_fn=<MseLossBackward0>)\n",
      "tensor(96473.1094, grad_fn=<MseLossBackward0>)\n",
      "tensor(94595.7500, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-25 14:43:13,658]\u001b[0m Trial 13 finished with value: 1069.722900390625 and parameters: {'n_layers': 3, 'n_h_0': 37, 'n_h_1': 36, 'n_h_2': 60, 'lr': 0.018436813724756335, 'n_epochs': 55695}. Best is trial 10 with value: 905.126953125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final valid loss: 1144307.0\n",
      "#################\n",
      "3\n",
      "Params:\n",
      "          n_layers: 3\n",
      "          n_hidden_units: [60, 1, 33]\n",
      "          lr: 0.0007205399924720446\n",
      "          n_epochs: 33812\n",
      "tensor(9494927., grad_fn=<MseLossBackward0>)\n",
      "tensor(9485486., grad_fn=<MseLossBackward0>)\n",
      "tensor(9472533., grad_fn=<MseLossBackward0>)\n",
      "tensor(9455856., grad_fn=<MseLossBackward0>)\n",
      "tensor(9435522., grad_fn=<MseLossBackward0>)\n",
      "tensor(9411632., grad_fn=<MseLossBackward0>)\n",
      "tensor(9384274., grad_fn=<MseLossBackward0>)\n",
      "tensor(9353431., grad_fn=<MseLossBackward0>)\n",
      "tensor(9319039., grad_fn=<MseLossBackward0>)\n",
      "tensor(9281191., grad_fn=<MseLossBackward0>)\n",
      "tensor(9240011., grad_fn=<MseLossBackward0>)\n",
      "tensor(9195618., grad_fn=<MseLossBackward0>)\n",
      "tensor(9148114., grad_fn=<MseLossBackward0>)\n",
      "tensor(9097604., grad_fn=<MseLossBackward0>)\n",
      "tensor(9044191., grad_fn=<MseLossBackward0>)\n",
      "tensor(8987971., grad_fn=<MseLossBackward0>)\n",
      "tensor(8929060., grad_fn=<MseLossBackward0>)\n",
      "tensor(8867567., grad_fn=<MseLossBackward0>)\n",
      "tensor(8803587., grad_fn=<MseLossBackward0>)\n",
      "tensor(8737215., grad_fn=<MseLossBackward0>)\n",
      "tensor(8668551., grad_fn=<MseLossBackward0>)\n",
      "tensor(8597715., grad_fn=<MseLossBackward0>)\n",
      "tensor(8524783., grad_fn=<MseLossBackward0>)\n",
      "tensor(8449879., grad_fn=<MseLossBackward0>)\n",
      "tensor(8373125.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(8294630.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(8214465., grad_fn=<MseLossBackward0>)\n",
      "tensor(8132547., grad_fn=<MseLossBackward0>)\n",
      "tensor(8049083.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(7964266., grad_fn=<MseLossBackward0>)\n",
      "tensor(7878216.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(7791048.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(7702891.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(7613869., grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-25 14:43:30,429]\u001b[0m Trial 14 finished with value: 2713.61181640625 and parameters: {'n_layers': 3, 'n_h_0': 60, 'n_h_1': 1, 'n_h_2': 33, 'lr': 0.0007205399924720446, 'n_epochs': 33812}. Best is trial 10 with value: 905.126953125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final valid loss: 7363689.0\n",
      "#################\n",
      "0\n",
      "Params:\n",
      "          n_layers: 0\n",
      "          n_hidden_units: []\n",
      "          lr: 0.10556182540566317\n",
      "          n_epochs: 89761\n",
      "tensor(9495638., grad_fn=<MseLossBackward0>)\n",
      "tensor(9326009., grad_fn=<MseLossBackward0>)\n",
      "tensor(9256459., grad_fn=<MseLossBackward0>)\n",
      "tensor(9203862., grad_fn=<MseLossBackward0>)\n",
      "tensor(9160037., grad_fn=<MseLossBackward0>)\n",
      "tensor(9121816., grad_fn=<MseLossBackward0>)\n",
      "tensor(9087573., grad_fn=<MseLossBackward0>)\n",
      "tensor(9056342., grad_fn=<MseLossBackward0>)\n",
      "tensor(9027497., grad_fn=<MseLossBackward0>)\n",
      "tensor(9000599., grad_fn=<MseLossBackward0>)\n",
      "tensor(8975330., grad_fn=<MseLossBackward0>)\n",
      "tensor(8951451., grad_fn=<MseLossBackward0>)\n",
      "tensor(8928775., grad_fn=<MseLossBackward0>)\n",
      "tensor(8907156., grad_fn=<MseLossBackward0>)\n",
      "tensor(8886470., grad_fn=<MseLossBackward0>)\n",
      "tensor(8866620., grad_fn=<MseLossBackward0>)\n",
      "tensor(8847521., grad_fn=<MseLossBackward0>)\n",
      "tensor(8829102., grad_fn=<MseLossBackward0>)\n",
      "tensor(8811306., grad_fn=<MseLossBackward0>)\n",
      "tensor(8794083., grad_fn=<MseLossBackward0>)\n",
      "tensor(8777387., grad_fn=<MseLossBackward0>)\n",
      "tensor(8761178., grad_fn=<MseLossBackward0>)\n",
      "tensor(8745423., grad_fn=<MseLossBackward0>)\n",
      "tensor(8730089., grad_fn=<MseLossBackward0>)\n",
      "tensor(8715150., grad_fn=<MseLossBackward0>)\n",
      "tensor(8700582., grad_fn=<MseLossBackward0>)\n",
      "tensor(8686362., grad_fn=<MseLossBackward0>)\n",
      "tensor(8672470., grad_fn=<MseLossBackward0>)\n",
      "tensor(8658889., grad_fn=<MseLossBackward0>)\n",
      "tensor(8645601., grad_fn=<MseLossBackward0>)\n",
      "tensor(8632591., grad_fn=<MseLossBackward0>)\n",
      "tensor(8619846., grad_fn=<MseLossBackward0>)\n",
      "tensor(8607352., grad_fn=<MseLossBackward0>)\n",
      "tensor(8595098., grad_fn=<MseLossBackward0>)\n",
      "tensor(8583072., grad_fn=<MseLossBackward0>)\n",
      "tensor(8571265., grad_fn=<MseLossBackward0>)\n",
      "tensor(8559666., grad_fn=<MseLossBackward0>)\n",
      "tensor(8548266., grad_fn=<MseLossBackward0>)\n",
      "tensor(8537059., grad_fn=<MseLossBackward0>)\n",
      "tensor(8526037., grad_fn=<MseLossBackward0>)\n",
      "tensor(8515189., grad_fn=<MseLossBackward0>)\n",
      "tensor(8504509., grad_fn=<MseLossBackward0>)\n",
      "tensor(8493992., grad_fn=<MseLossBackward0>)\n",
      "tensor(8483630., grad_fn=<MseLossBackward0>)\n",
      "tensor(8473424., grad_fn=<MseLossBackward0>)\n",
      "tensor(8463361., grad_fn=<MseLossBackward0>)\n",
      "tensor(8453445., grad_fn=<MseLossBackward0>)\n",
      "tensor(8443663., grad_fn=<MseLossBackward0>)\n",
      "tensor(8434017., grad_fn=<MseLossBackward0>)\n",
      "tensor(8424501., grad_fn=<MseLossBackward0>)\n",
      "tensor(8415110., grad_fn=<MseLossBackward0>)\n",
      "tensor(8405841., grad_fn=<MseLossBackward0>)\n",
      "tensor(8396687., grad_fn=<MseLossBackward0>)\n",
      "tensor(8387651., grad_fn=<MseLossBackward0>)\n",
      "tensor(8378723.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(8369905.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(8361193., grad_fn=<MseLossBackward0>)\n",
      "tensor(8352582., grad_fn=<MseLossBackward0>)\n",
      "tensor(8344071.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(8335655., grad_fn=<MseLossBackward0>)\n",
      "tensor(8327335., grad_fn=<MseLossBackward0>)\n",
      "tensor(8319108., grad_fn=<MseLossBackward0>)\n",
      "tensor(8310970., grad_fn=<MseLossBackward0>)\n",
      "tensor(8302919.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(8294955., grad_fn=<MseLossBackward0>)\n",
      "tensor(8287073., grad_fn=<MseLossBackward0>)\n",
      "tensor(8279270., grad_fn=<MseLossBackward0>)\n",
      "tensor(8271547.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(8263906., grad_fn=<MseLossBackward0>)\n",
      "tensor(8256338.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(8248842., grad_fn=<MseLossBackward0>)\n",
      "tensor(8241419.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(8234069., grad_fn=<MseLossBackward0>)\n",
      "tensor(8226785., grad_fn=<MseLossBackward0>)\n",
      "tensor(8219571.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(8212424.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(8205341.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(8198321., grad_fn=<MseLossBackward0>)\n",
      "tensor(8191368., grad_fn=<MseLossBackward0>)\n",
      "tensor(8184472.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(8177635.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(8170862., grad_fn=<MseLossBackward0>)\n",
      "tensor(8164139., grad_fn=<MseLossBackward0>)\n",
      "tensor(8157481., grad_fn=<MseLossBackward0>)\n",
      "tensor(8150872., grad_fn=<MseLossBackward0>)\n",
      "tensor(8144320.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(8137826., grad_fn=<MseLossBackward0>)\n",
      "tensor(8131374.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(8124980., grad_fn=<MseLossBackward0>)\n",
      "tensor(8118635., grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-25 14:43:37,644]\u001b[0m Trial 15 finished with value: 2814.10498046875 and parameters: {'n_layers': 0, 'lr': 0.10556182540566317, 'n_epochs': 89761}. Best is trial 10 with value: 905.126953125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final valid loss: 7919187.0\n",
      "#################\n",
      "3\n",
      "Params:\n",
      "          n_layers: 3\n",
      "          n_hidden_units: [44, 99, 99]\n",
      "          lr: 0.0009991450988346797\n",
      "          n_epochs: 5537\n",
      "tensor(9496680., grad_fn=<MseLossBackward0>)\n",
      "tensor(7977422.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(5146032., grad_fn=<MseLossBackward0>)\n",
      "tensor(3135366.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(2262713.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(1910363.1250, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-25 14:43:42,636]\u001b[0m Trial 16 finished with value: 1426.623046875 and parameters: {'n_layers': 3, 'n_h_0': 44, 'n_h_1': 99, 'n_h_2': 99, 'lr': 0.0009991450988346797, 'n_epochs': 5537}. Best is trial 10 with value: 905.126953125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final valid loss: 2035253.375\n",
      "#################\n",
      "1\n",
      "Params:\n",
      "          n_layers: 1\n",
      "          n_hidden_units: [21]\n",
      "          lr: 0.010241839671891299\n",
      "          n_epochs: 58430\n",
      "tensor(9495751., grad_fn=<MseLossBackward0>)\n",
      "tensor(9125443., grad_fn=<MseLossBackward0>)\n",
      "tensor(8762312., grad_fn=<MseLossBackward0>)\n",
      "tensor(8416325., grad_fn=<MseLossBackward0>)\n",
      "tensor(8086725.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(7773101.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(7474946.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(7191674.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(6922742., grad_fn=<MseLossBackward0>)\n",
      "tensor(6667507., grad_fn=<MseLossBackward0>)\n",
      "tensor(6425351.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(6195697., grad_fn=<MseLossBackward0>)\n",
      "tensor(5977945., grad_fn=<MseLossBackward0>)\n",
      "tensor(5771539.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(5575950.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(5390628.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(5215158.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(5049065.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(4891843., grad_fn=<MseLossBackward0>)\n",
      "tensor(4743004., grad_fn=<MseLossBackward0>)\n",
      "tensor(4602149.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(4468915., grad_fn=<MseLossBackward0>)\n",
      "tensor(4342860., grad_fn=<MseLossBackward0>)\n",
      "tensor(4223596., grad_fn=<MseLossBackward0>)\n",
      "tensor(4110770.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(4004020.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(3903037.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(3807474.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(3717012., grad_fn=<MseLossBackward0>)\n",
      "tensor(3631346.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(3550211.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(3473343.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(3400412.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(3331180.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(3265460.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(3202999.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(3143652.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(3087230.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(3033515.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(2982338.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(2933588.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(2887046., grad_fn=<MseLossBackward0>)\n",
      "tensor(2842631.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(2800192.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(2759654.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(2720902.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(2683820.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(2648272.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(2614039.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(2581135., grad_fn=<MseLossBackward0>)\n",
      "tensor(2549523.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(2519112.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(2489893.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(2461757.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(2434692.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(2408619., grad_fn=<MseLossBackward0>)\n",
      "tensor(2383514.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(2359339.7500, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-25 14:43:52,472]\u001b[0m Trial 17 finished with value: 1591.6282958984375 and parameters: {'n_layers': 1, 'n_h_0': 21, 'lr': 0.010241839671891299, 'n_epochs': 58430}. Best is trial 10 with value: 905.126953125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2336030.7500, grad_fn=<MseLossBackward0>)\n",
      "Final valid loss: 2533280.5\n",
      "#################\n",
      "3\n",
      "Params:\n",
      "          n_layers: 3\n",
      "          n_hidden_units: [60, 40, 7]\n",
      "          lr: 0.48947991033166127\n",
      "          n_epochs: 23584\n",
      "tensor(9495950., grad_fn=<MseLossBackward0>)\n",
      "tensor(536932.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(399711.6250, grad_fn=<MseLossBackward0>)\n",
      "tensor(316271.5312, grad_fn=<MseLossBackward0>)\n",
      "tensor(257168.5938, grad_fn=<MseLossBackward0>)\n",
      "tensor(205870.2969, grad_fn=<MseLossBackward0>)\n",
      "tensor(171267.1875, grad_fn=<MseLossBackward0>)\n",
      "tensor(160489.0156, grad_fn=<MseLossBackward0>)\n",
      "tensor(131510.7344, grad_fn=<MseLossBackward0>)\n",
      "tensor(115400.0547, grad_fn=<MseLossBackward0>)\n",
      "tensor(104529.3594, grad_fn=<MseLossBackward0>)\n",
      "tensor(92541.9375, grad_fn=<MseLossBackward0>)\n",
      "tensor(90239.1094, grad_fn=<MseLossBackward0>)\n",
      "tensor(92923.5312, grad_fn=<MseLossBackward0>)\n",
      "tensor(81395.1172, grad_fn=<MseLossBackward0>)\n",
      "tensor(79000.8594, grad_fn=<MseLossBackward0>)\n",
      "tensor(71310.7969, grad_fn=<MseLossBackward0>)\n",
      "tensor(70987.0547, grad_fn=<MseLossBackward0>)\n",
      "tensor(66938.5469, grad_fn=<MseLossBackward0>)\n",
      "tensor(65487.4844, grad_fn=<MseLossBackward0>)\n",
      "tensor(65972.3594, grad_fn=<MseLossBackward0>)\n",
      "tensor(62137.3047, grad_fn=<MseLossBackward0>)\n",
      "tensor(58434.0586, grad_fn=<MseLossBackward0>)\n",
      "tensor(57914.3438, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-25 14:44:06,266]\u001b[0m Trial 18 finished with value: 1208.7030029296875 and parameters: {'n_layers': 3, 'n_h_0': 60, 'n_h_1': 40, 'n_h_2': 7, 'lr': 0.48947991033166127, 'n_epochs': 23584}. Best is trial 10 with value: 905.126953125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final valid loss: 1460963.0\n",
      "#################\n",
      "2\n",
      "Params:\n",
      "          n_layers: 2\n",
      "          n_hidden_units: [49, 72]\n",
      "          lr: 0.0008116970767319741\n",
      "          n_epochs: 36619\n",
      "tensor(9496134., grad_fn=<MseLossBackward0>)\n",
      "tensor(9437412., grad_fn=<MseLossBackward0>)\n",
      "tensor(9349835., grad_fn=<MseLossBackward0>)\n",
      "tensor(9241966., grad_fn=<MseLossBackward0>)\n",
      "tensor(9118231., grad_fn=<MseLossBackward0>)\n",
      "tensor(8981553., grad_fn=<MseLossBackward0>)\n",
      "tensor(8834094., grad_fn=<MseLossBackward0>)\n",
      "tensor(8677694., grad_fn=<MseLossBackward0>)\n",
      "tensor(8513885., grad_fn=<MseLossBackward0>)\n",
      "tensor(8344116., grad_fn=<MseLossBackward0>)\n",
      "tensor(8169557., grad_fn=<MseLossBackward0>)\n",
      "tensor(7991293.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(7810351.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(7627633.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(7443964.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(7260119., grad_fn=<MseLossBackward0>)\n",
      "tensor(7076811., grad_fn=<MseLossBackward0>)\n",
      "tensor(6894650., grad_fn=<MseLossBackward0>)\n",
      "tensor(6714208., grad_fn=<MseLossBackward0>)\n",
      "tensor(6535959., grad_fn=<MseLossBackward0>)\n",
      "tensor(6360360.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(6187774., grad_fn=<MseLossBackward0>)\n",
      "tensor(6018495., grad_fn=<MseLossBackward0>)\n",
      "tensor(5852825., grad_fn=<MseLossBackward0>)\n",
      "tensor(5690975.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(5533095.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(5379314., grad_fn=<MseLossBackward0>)\n",
      "tensor(5229761., grad_fn=<MseLossBackward0>)\n",
      "tensor(5084524., grad_fn=<MseLossBackward0>)\n",
      "tensor(4943601.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(4807023., grad_fn=<MseLossBackward0>)\n",
      "tensor(4674770.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(4546806., grad_fn=<MseLossBackward0>)\n",
      "tensor(4423097., grad_fn=<MseLossBackward0>)\n",
      "tensor(4303610.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(4188248.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(4076968.7500, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-25 14:44:27,776]\u001b[0m Trial 19 finished with value: 1997.413330078125 and parameters: {'n_layers': 2, 'n_h_0': 49, 'n_h_1': 72, 'lr': 0.0008116970767319741, 'n_epochs': 36619}. Best is trial 10 with value: 905.126953125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final valid loss: 3989660.25\n",
      "#################\n",
      "3\n",
      "Params:\n",
      "          n_layers: 3\n",
      "          n_hidden_units: [72, 16, 54]\n",
      "          lr: 0.07447066715529675\n",
      "          n_epochs: 61864\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-25 14:45:03,703]\u001b[0m Trial 20 finished with value: 3057.548095703125 and parameters: {'n_layers': 3, 'n_h_0': 72, 'n_h_1': 16, 'n_h_2': 54, 'lr': 0.07447066715529675, 'n_epochs': 61864}. Best is trial 10 with value: 905.126953125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final valid loss: 9348601.0\n",
      "#################\n",
      "3\n",
      "Params:\n",
      "          n_layers: 3\n",
      "          n_hidden_units: [36, 39, 63]\n",
      "          lr: 0.015514618594816615\n",
      "          n_epochs: 58057\n",
      "tensor(9496923., grad_fn=<MseLossBackward0>)\n",
      "tensor(792114.6250, grad_fn=<MseLossBackward0>)\n",
      "tensor(718880.5625, grad_fn=<MseLossBackward0>)\n",
      "tensor(683376., grad_fn=<MseLossBackward0>)\n",
      "tensor(655851.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(628703.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(592357.8750, grad_fn=<MseLossBackward0>)\n",
      "tensor(557649.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(521993.7812, grad_fn=<MseLossBackward0>)\n",
      "tensor(488734.0625, grad_fn=<MseLossBackward0>)\n",
      "tensor(459335.4375, grad_fn=<MseLossBackward0>)\n",
      "tensor(432830.1562, grad_fn=<MseLossBackward0>)\n",
      "tensor(410095.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(389537.3750, grad_fn=<MseLossBackward0>)\n",
      "tensor(370808.6562, grad_fn=<MseLossBackward0>)\n",
      "tensor(352800.4688, grad_fn=<MseLossBackward0>)\n",
      "tensor(335893.5938, grad_fn=<MseLossBackward0>)\n",
      "tensor(319521.5312, grad_fn=<MseLossBackward0>)\n",
      "tensor(305623.5312, grad_fn=<MseLossBackward0>)\n",
      "tensor(292769.4375, grad_fn=<MseLossBackward0>)\n",
      "tensor(280596.4688, grad_fn=<MseLossBackward0>)\n",
      "tensor(270440.4688, grad_fn=<MseLossBackward0>)\n",
      "tensor(262512.2188, grad_fn=<MseLossBackward0>)\n",
      "tensor(255367.0625, grad_fn=<MseLossBackward0>)\n",
      "tensor(248921.5781, grad_fn=<MseLossBackward0>)\n",
      "tensor(242660.4844, grad_fn=<MseLossBackward0>)\n",
      "tensor(237720.8125, grad_fn=<MseLossBackward0>)\n",
      "tensor(232733.0469, grad_fn=<MseLossBackward0>)\n",
      "tensor(227733.7031, grad_fn=<MseLossBackward0>)\n",
      "tensor(223136.5156, grad_fn=<MseLossBackward0>)\n",
      "tensor(218907.2812, grad_fn=<MseLossBackward0>)\n",
      "tensor(214540.8594, grad_fn=<MseLossBackward0>)\n",
      "tensor(210742.9219, grad_fn=<MseLossBackward0>)\n",
      "tensor(206624.1562, grad_fn=<MseLossBackward0>)\n",
      "tensor(201434.9219, grad_fn=<MseLossBackward0>)\n",
      "tensor(197302.4531, grad_fn=<MseLossBackward0>)\n",
      "tensor(193466.2969, grad_fn=<MseLossBackward0>)\n",
      "tensor(190027.8594, grad_fn=<MseLossBackward0>)\n",
      "tensor(186908.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor(183783.4688, grad_fn=<MseLossBackward0>)\n",
      "tensor(180280.8750, grad_fn=<MseLossBackward0>)\n",
      "tensor(176529.0156, grad_fn=<MseLossBackward0>)\n",
      "tensor(173076.9219, grad_fn=<MseLossBackward0>)\n",
      "tensor(170019.8906, grad_fn=<MseLossBackward0>)\n",
      "tensor(167107.4844, grad_fn=<MseLossBackward0>)\n",
      "tensor(164660.3906, grad_fn=<MseLossBackward0>)\n",
      "tensor(162237.1250, grad_fn=<MseLossBackward0>)\n",
      "tensor(159860.3594, grad_fn=<MseLossBackward0>)\n",
      "tensor(157842.7969, grad_fn=<MseLossBackward0>)\n",
      "tensor(155868.2812, grad_fn=<MseLossBackward0>)\n",
      "tensor(154249.2031, grad_fn=<MseLossBackward0>)\n",
      "tensor(152907.8906, grad_fn=<MseLossBackward0>)\n",
      "tensor(151693.2344, grad_fn=<MseLossBackward0>)\n",
      "tensor(150491.0625, grad_fn=<MseLossBackward0>)\n",
      "tensor(149028.2344, grad_fn=<MseLossBackward0>)\n",
      "tensor(147734.4531, grad_fn=<MseLossBackward0>)\n",
      "tensor(146430.1875, grad_fn=<MseLossBackward0>)\n",
      "tensor(145057.6250, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-25 14:45:42,826]\u001b[0m Trial 21 finished with value: 1014.9299926757812 and parameters: {'n_layers': 3, 'n_h_0': 36, 'n_h_1': 39, 'n_h_2': 63, 'lr': 0.015514618594816615, 'n_epochs': 58057}. Best is trial 10 with value: 905.126953125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(143820.5000, grad_fn=<MseLossBackward0>)\n",
      "Final valid loss: 1030082.9375\n",
      "#################\n",
      "3\n",
      "Params:\n",
      "          n_layers: 3\n",
      "          n_hidden_units: [24, 43, 74]\n",
      "          lr: 0.010775276784238239\n",
      "          n_epochs: 45392\n",
      "tensor(9497143., grad_fn=<MseLossBackward0>)\n",
      "tensor(925930.1875, grad_fn=<MseLossBackward0>)\n",
      "tensor(812126.1250, grad_fn=<MseLossBackward0>)\n",
      "tensor(762751.6875, grad_fn=<MseLossBackward0>)\n",
      "tensor(729000.3125, grad_fn=<MseLossBackward0>)\n",
      "tensor(702865.1875, grad_fn=<MseLossBackward0>)\n",
      "tensor(681068.6250, grad_fn=<MseLossBackward0>)\n",
      "tensor(666342.0625, grad_fn=<MseLossBackward0>)\n",
      "tensor(653377.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(641374.4375, grad_fn=<MseLossBackward0>)\n",
      "tensor(631179.3125, grad_fn=<MseLossBackward0>)\n",
      "tensor(622816.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(615635.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(608658.1875, grad_fn=<MseLossBackward0>)\n",
      "tensor(602365.9375, grad_fn=<MseLossBackward0>)\n",
      "tensor(596465.1875, grad_fn=<MseLossBackward0>)\n",
      "tensor(589802.1250, grad_fn=<MseLossBackward0>)\n",
      "tensor(583464.6875, grad_fn=<MseLossBackward0>)\n",
      "tensor(576877.1875, grad_fn=<MseLossBackward0>)\n",
      "tensor(570791.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(564976.4375, grad_fn=<MseLossBackward0>)\n",
      "tensor(559050.1875, grad_fn=<MseLossBackward0>)\n",
      "tensor(552990.8125, grad_fn=<MseLossBackward0>)\n",
      "tensor(546350., grad_fn=<MseLossBackward0>)\n",
      "tensor(540558.1875, grad_fn=<MseLossBackward0>)\n",
      "tensor(534773.4375, grad_fn=<MseLossBackward0>)\n",
      "tensor(528873.8125, grad_fn=<MseLossBackward0>)\n",
      "tensor(524298.6250, grad_fn=<MseLossBackward0>)\n",
      "tensor(519814.2188, grad_fn=<MseLossBackward0>)\n",
      "tensor(515572.5312, grad_fn=<MseLossBackward0>)\n",
      "tensor(511959.4375, grad_fn=<MseLossBackward0>)\n",
      "tensor(508538.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(504787.6562, grad_fn=<MseLossBackward0>)\n",
      "tensor(500633.6250, grad_fn=<MseLossBackward0>)\n",
      "tensor(497364.3438, grad_fn=<MseLossBackward0>)\n",
      "tensor(494532.3750, grad_fn=<MseLossBackward0>)\n",
      "tensor(491876.0312, grad_fn=<MseLossBackward0>)\n",
      "tensor(489195.6250, grad_fn=<MseLossBackward0>)\n",
      "tensor(486831.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(484532.4688, grad_fn=<MseLossBackward0>)\n",
      "tensor(480985.3125, grad_fn=<MseLossBackward0>)\n",
      "tensor(478624.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(476649.1875, grad_fn=<MseLossBackward0>)\n",
      "tensor(474201.8438, grad_fn=<MseLossBackward0>)\n",
      "tensor(471843.6562, grad_fn=<MseLossBackward0>)\n",
      "tensor(469976.2188, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-25 14:46:11,892]\u001b[0m Trial 22 finished with value: 933.3225708007812 and parameters: {'n_layers': 3, 'n_h_0': 24, 'n_h_1': 43, 'n_h_2': 74, 'lr': 0.010775276784238239, 'n_epochs': 45392}. Best is trial 10 with value: 905.126953125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final valid loss: 871091.0625\n",
      "#################\n",
      "3\n",
      "Params:\n",
      "          n_layers: 3\n",
      "          n_hidden_units: [22, 64, 86]\n",
      "          lr: 0.006016377752319457\n",
      "          n_epochs: 83140\n",
      "tensor(9497017., grad_fn=<MseLossBackward0>)\n",
      "tensor(1171613.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(1000120.0625, grad_fn=<MseLossBackward0>)\n",
      "tensor(923314.9375, grad_fn=<MseLossBackward0>)\n",
      "tensor(875468., grad_fn=<MseLossBackward0>)\n",
      "tensor(839266.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(810418.8125, grad_fn=<MseLossBackward0>)\n",
      "tensor(788705.1250, grad_fn=<MseLossBackward0>)\n",
      "tensor(772341.3750, grad_fn=<MseLossBackward0>)\n",
      "tensor(758108.3125, grad_fn=<MseLossBackward0>)\n",
      "tensor(743727.0625, grad_fn=<MseLossBackward0>)\n",
      "tensor(730416.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(718577.6875, grad_fn=<MseLossBackward0>)\n",
      "tensor(707724.8125, grad_fn=<MseLossBackward0>)\n",
      "tensor(697632.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(688632.8125, grad_fn=<MseLossBackward0>)\n",
      "tensor(680260.8125, grad_fn=<MseLossBackward0>)\n",
      "tensor(671759.4375, grad_fn=<MseLossBackward0>)\n",
      "tensor(663918.1250, grad_fn=<MseLossBackward0>)\n",
      "tensor(656604., grad_fn=<MseLossBackward0>)\n",
      "tensor(649263.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(642443.6875, grad_fn=<MseLossBackward0>)\n",
      "tensor(635971.3125, grad_fn=<MseLossBackward0>)\n",
      "tensor(629632., grad_fn=<MseLossBackward0>)\n",
      "tensor(623099.6250, grad_fn=<MseLossBackward0>)\n",
      "tensor(616720.3750, grad_fn=<MseLossBackward0>)\n",
      "tensor(610411.1875, grad_fn=<MseLossBackward0>)\n",
      "tensor(604427.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(598372.1250, grad_fn=<MseLossBackward0>)\n",
      "tensor(592396.5625, grad_fn=<MseLossBackward0>)\n",
      "tensor(585796.8125, grad_fn=<MseLossBackward0>)\n",
      "tensor(578220.8125, grad_fn=<MseLossBackward0>)\n",
      "tensor(571077.8750, grad_fn=<MseLossBackward0>)\n",
      "tensor(564176.6250, grad_fn=<MseLossBackward0>)\n",
      "tensor(557043.1250, grad_fn=<MseLossBackward0>)\n",
      "tensor(549930.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(542715.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(535573.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(528385.1250, grad_fn=<MseLossBackward0>)\n",
      "tensor(521325.0312, grad_fn=<MseLossBackward0>)\n",
      "tensor(514334.7188, grad_fn=<MseLossBackward0>)\n",
      "tensor(507539.8125, grad_fn=<MseLossBackward0>)\n",
      "tensor(501264.6562, grad_fn=<MseLossBackward0>)\n",
      "tensor(495258.4375, grad_fn=<MseLossBackward0>)\n",
      "tensor(489182.3750, grad_fn=<MseLossBackward0>)\n",
      "tensor(483507.9688, grad_fn=<MseLossBackward0>)\n",
      "tensor(477794.6875, grad_fn=<MseLossBackward0>)\n",
      "tensor(472355.8750, grad_fn=<MseLossBackward0>)\n",
      "tensor(466976.4688, grad_fn=<MseLossBackward0>)\n",
      "tensor(461975.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(456941.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(451291.6250, grad_fn=<MseLossBackward0>)\n",
      "tensor(445281.8750, grad_fn=<MseLossBackward0>)\n",
      "tensor(439790.3750, grad_fn=<MseLossBackward0>)\n",
      "tensor(434857.7188, grad_fn=<MseLossBackward0>)\n",
      "tensor(429840.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(425265.1562, grad_fn=<MseLossBackward0>)\n",
      "tensor(420672., grad_fn=<MseLossBackward0>)\n",
      "tensor(416044.4688, grad_fn=<MseLossBackward0>)\n",
      "tensor(412010.6875, grad_fn=<MseLossBackward0>)\n",
      "tensor(408151.5312, grad_fn=<MseLossBackward0>)\n",
      "tensor(404538.8750, grad_fn=<MseLossBackward0>)\n",
      "tensor(401159.3750, grad_fn=<MseLossBackward0>)\n",
      "tensor(398024.2812, grad_fn=<MseLossBackward0>)\n",
      "tensor(394723.5312, grad_fn=<MseLossBackward0>)\n",
      "tensor(391441.8750, grad_fn=<MseLossBackward0>)\n",
      "tensor(388396.1250, grad_fn=<MseLossBackward0>)\n",
      "tensor(385589.9375, grad_fn=<MseLossBackward0>)\n",
      "tensor(382821.6562, grad_fn=<MseLossBackward0>)\n",
      "tensor(380003.5312, grad_fn=<MseLossBackward0>)\n",
      "tensor(377291.3750, grad_fn=<MseLossBackward0>)\n",
      "tensor(374505.5312, grad_fn=<MseLossBackward0>)\n",
      "tensor(371993.6250, grad_fn=<MseLossBackward0>)\n",
      "tensor(369569.3125, grad_fn=<MseLossBackward0>)\n",
      "tensor(367207.0312, grad_fn=<MseLossBackward0>)\n",
      "tensor(364786.2188, grad_fn=<MseLossBackward0>)\n",
      "tensor(362531.5312, grad_fn=<MseLossBackward0>)\n",
      "tensor(360289.7812, grad_fn=<MseLossBackward0>)\n",
      "tensor(358113.0625, grad_fn=<MseLossBackward0>)\n",
      "tensor(355931.0625, grad_fn=<MseLossBackward0>)\n",
      "tensor(353904.4688, grad_fn=<MseLossBackward0>)\n",
      "tensor(352027.3125, grad_fn=<MseLossBackward0>)\n",
      "tensor(350128.5312, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-25 14:47:05,590]\u001b[0m Trial 23 finished with value: 871.9281616210938 and parameters: {'n_layers': 3, 'n_h_0': 22, 'n_h_1': 64, 'n_h_2': 86, 'lr': 0.006016377752319457, 'n_epochs': 83140}. Best is trial 23 with value: 871.9281616210938.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(348284.6875, grad_fn=<MseLossBackward0>)\n",
      "Final valid loss: 760258.6875\n",
      "#################\n",
      "2\n",
      "Params:\n",
      "          n_layers: 2\n",
      "          n_hidden_units: [42, 66]\n",
      "          lr: 0.0027540249910313072\n",
      "          n_epochs: 82047\n",
      "tensor(9497126., grad_fn=<MseLossBackward0>)\n",
      "tensor(8272772., grad_fn=<MseLossBackward0>)\n",
      "tensor(6479374.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(4908023., grad_fn=<MseLossBackward0>)\n",
      "tensor(3739771.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(2944042.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(2437111.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(2121111.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(1919596.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(1785034.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(1689094.3750, grad_fn=<MseLossBackward0>)\n",
      "tensor(1617001.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(1560425.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(1513443., grad_fn=<MseLossBackward0>)\n",
      "tensor(1472967.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(1437644.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(1406294.3750, grad_fn=<MseLossBackward0>)\n",
      "tensor(1377979.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(1351861.8750, grad_fn=<MseLossBackward0>)\n",
      "tensor(1327955., grad_fn=<MseLossBackward0>)\n",
      "tensor(1305592.8750, grad_fn=<MseLossBackward0>)\n",
      "tensor(1284386.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(1264480.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(1245874.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(1228524.6250, grad_fn=<MseLossBackward0>)\n",
      "tensor(1212185., grad_fn=<MseLossBackward0>)\n",
      "tensor(1196773.6250, grad_fn=<MseLossBackward0>)\n",
      "tensor(1182230.3750, grad_fn=<MseLossBackward0>)\n",
      "tensor(1168323.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(1155104.8750, grad_fn=<MseLossBackward0>)\n",
      "tensor(1142485., grad_fn=<MseLossBackward0>)\n",
      "tensor(1130532.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(1119259.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(1108636.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(1098598.8750, grad_fn=<MseLossBackward0>)\n",
      "tensor(1088911.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(1079584.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(1070709.3750, grad_fn=<MseLossBackward0>)\n",
      "tensor(1062143.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(1053951.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(1046124.6250, grad_fn=<MseLossBackward0>)\n",
      "tensor(1038622.3750, grad_fn=<MseLossBackward0>)\n",
      "tensor(1031407.5625, grad_fn=<MseLossBackward0>)\n",
      "tensor(1024326.8125, grad_fn=<MseLossBackward0>)\n",
      "tensor(1017638.1250, grad_fn=<MseLossBackward0>)\n",
      "tensor(1011295.1875, grad_fn=<MseLossBackward0>)\n",
      "tensor(1005261.4375, grad_fn=<MseLossBackward0>)\n",
      "tensor(999431.9375, grad_fn=<MseLossBackward0>)\n",
      "tensor(993852.3125, grad_fn=<MseLossBackward0>)\n",
      "tensor(988542.8750, grad_fn=<MseLossBackward0>)\n",
      "tensor(983473.3125, grad_fn=<MseLossBackward0>)\n",
      "tensor(978621.6250, grad_fn=<MseLossBackward0>)\n",
      "tensor(973968.1250, grad_fn=<MseLossBackward0>)\n",
      "tensor(969502.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(965155.4375, grad_fn=<MseLossBackward0>)\n",
      "tensor(960929.3125, grad_fn=<MseLossBackward0>)\n",
      "tensor(956819.1875, grad_fn=<MseLossBackward0>)\n",
      "tensor(952886., grad_fn=<MseLossBackward0>)\n",
      "tensor(949085.0625, grad_fn=<MseLossBackward0>)\n",
      "tensor(945395.6875, grad_fn=<MseLossBackward0>)\n",
      "tensor(941783.9375, grad_fn=<MseLossBackward0>)\n",
      "tensor(938263.9375, grad_fn=<MseLossBackward0>)\n",
      "tensor(934818.4375, grad_fn=<MseLossBackward0>)\n",
      "tensor(931454.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(928176., grad_fn=<MseLossBackward0>)\n",
      "tensor(924954.1875, grad_fn=<MseLossBackward0>)\n",
      "tensor(921792.1875, grad_fn=<MseLossBackward0>)\n",
      "tensor(918706.8750, grad_fn=<MseLossBackward0>)\n",
      "tensor(915728.4375, grad_fn=<MseLossBackward0>)\n",
      "tensor(912816.4375, grad_fn=<MseLossBackward0>)\n",
      "tensor(909971.3750, grad_fn=<MseLossBackward0>)\n",
      "tensor(907149.8750, grad_fn=<MseLossBackward0>)\n",
      "tensor(904290.4375, grad_fn=<MseLossBackward0>)\n",
      "tensor(901460.3750, grad_fn=<MseLossBackward0>)\n",
      "tensor(898712.3750, grad_fn=<MseLossBackward0>)\n",
      "tensor(896052.8125, grad_fn=<MseLossBackward0>)\n",
      "tensor(893434.3750, grad_fn=<MseLossBackward0>)\n",
      "tensor(890835.1875, grad_fn=<MseLossBackward0>)\n",
      "tensor(888301.3750, grad_fn=<MseLossBackward0>)\n",
      "tensor(885806.1875, grad_fn=<MseLossBackward0>)\n",
      "tensor(883357.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(880971.4375, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-25 14:47:46,296]\u001b[0m Trial 24 finished with value: 999.8745727539062 and parameters: {'n_layers': 2, 'n_h_0': 42, 'n_h_1': 66, 'lr': 0.0027540249910313072, 'n_epochs': 82047}. Best is trial 23 with value: 871.9281616210938.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(878657.1250, grad_fn=<MseLossBackward0>)\n",
      "Final valid loss: 999749.125\n",
      "#################\n",
      "3\n",
      "Params:\n",
      "          n_layers: 3\n",
      "          n_hidden_units: [15, 76, 100]\n",
      "          lr: 0.0003171445838498449\n",
      "          n_epochs: 99502\n",
      "tensor(9497111., grad_fn=<MseLossBackward0>)\n",
      "tensor(9487158., grad_fn=<MseLossBackward0>)\n",
      "tensor(9472587., grad_fn=<MseLossBackward0>)\n",
      "tensor(9451269., grad_fn=<MseLossBackward0>)\n",
      "tensor(9422735., grad_fn=<MseLossBackward0>)\n",
      "tensor(9386789., grad_fn=<MseLossBackward0>)\n",
      "tensor(9343450., grad_fn=<MseLossBackward0>)\n",
      "tensor(9292766., grad_fn=<MseLossBackward0>)\n",
      "tensor(9235120., grad_fn=<MseLossBackward0>)\n",
      "tensor(9170699., grad_fn=<MseLossBackward0>)\n",
      "tensor(9099786., grad_fn=<MseLossBackward0>)\n",
      "tensor(9022599., grad_fn=<MseLossBackward0>)\n",
      "tensor(8939342., grad_fn=<MseLossBackward0>)\n",
      "tensor(8850464., grad_fn=<MseLossBackward0>)\n",
      "tensor(8756260., grad_fn=<MseLossBackward0>)\n",
      "tensor(8657042., grad_fn=<MseLossBackward0>)\n",
      "tensor(8553176., grad_fn=<MseLossBackward0>)\n",
      "tensor(8444987., grad_fn=<MseLossBackward0>)\n",
      "tensor(8332823., grad_fn=<MseLossBackward0>)\n",
      "tensor(8217044., grad_fn=<MseLossBackward0>)\n",
      "tensor(8097987.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(7976017.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(7851482.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(7724722.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(7596092.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(7465902.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(7334468.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(7202087., grad_fn=<MseLossBackward0>)\n",
      "tensor(7069044.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(6935643.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(6802226.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(6669035., grad_fn=<MseLossBackward0>)\n",
      "tensor(6536308., grad_fn=<MseLossBackward0>)\n",
      "tensor(6404315.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(6273276.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(6143385.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(6014846.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(5887857.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(5762577.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(5639169., grad_fn=<MseLossBackward0>)\n",
      "tensor(5517747., grad_fn=<MseLossBackward0>)\n",
      "tensor(5398440., grad_fn=<MseLossBackward0>)\n",
      "tensor(5281344., grad_fn=<MseLossBackward0>)\n",
      "tensor(5166594.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(5054211.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(4944226., grad_fn=<MseLossBackward0>)\n",
      "tensor(4836726., grad_fn=<MseLossBackward0>)\n",
      "tensor(4731803.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(4629507.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(4529856.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(4432890.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(4338611., grad_fn=<MseLossBackward0>)\n",
      "tensor(4247045.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(4158203., grad_fn=<MseLossBackward0>)\n",
      "tensor(4072071.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(3988588.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(3907752., grad_fn=<MseLossBackward0>)\n",
      "tensor(3829542., grad_fn=<MseLossBackward0>)\n",
      "tensor(3753886.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(3680795.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(3610234.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(3542152.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(3476540., grad_fn=<MseLossBackward0>)\n",
      "tensor(3413273.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(3352333.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(3293672., grad_fn=<MseLossBackward0>)\n",
      "tensor(3237222., grad_fn=<MseLossBackward0>)\n",
      "tensor(3182906.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(3130586.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(3080234.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(3031836.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(2985319.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(2940623., grad_fn=<MseLossBackward0>)\n",
      "tensor(2897676., grad_fn=<MseLossBackward0>)\n",
      "tensor(2856384.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(2816706.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(2778488.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(2741686.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(2706283.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(2672146.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(2639315., grad_fn=<MseLossBackward0>)\n",
      "tensor(2607742.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(2577416.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(2548249.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(2520192.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(2493199., grad_fn=<MseLossBackward0>)\n",
      "tensor(2467211.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(2442182.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(2418075.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(2394838.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(2372438.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(2350839.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(2330024.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(2309870.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(2290461., grad_fn=<MseLossBackward0>)\n",
      "tensor(2271752.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(2253677.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(2236221.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(2219326., grad_fn=<MseLossBackward0>)\n",
      "tensor(2203006.5000, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-25 14:48:59,420]\u001b[0m Trial 25 finished with value: 1588.843017578125 and parameters: {'n_layers': 3, 'n_h_0': 15, 'n_h_1': 76, 'n_h_2': 100, 'lr': 0.0003171445838498449, 'n_epochs': 99502}. Best is trial 23 with value: 871.9281616210938.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final valid loss: 2524422.0\n",
      "#################\n",
      "2\n",
      "Params:\n",
      "          n_layers: 2\n",
      "          n_hidden_units: [1, 52]\n",
      "          lr: 0.11194790219030716\n",
      "          n_epochs: 71526\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-25 14:49:22,822]\u001b[0m Trial 26 finished with value: 3057.548095703125 and parameters: {'n_layers': 2, 'n_h_0': 1, 'n_h_1': 52, 'lr': 0.11194790219030716, 'n_epochs': 71526}. Best is trial 23 with value: 871.9281616210938.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9497148., grad_fn=<MseLossBackward0>)\n",
      "Final valid loss: 9348601.0\n",
      "#################\n",
      "3\n",
      "Params:\n",
      "          n_layers: 3\n",
      "          n_hidden_units: [23, 61, 34]\n",
      "          lr: 0.00586695277364326\n",
      "          n_epochs: 88143\n",
      "tensor(9496862., grad_fn=<MseLossBackward0>)\n",
      "tensor(1358856.3750, grad_fn=<MseLossBackward0>)\n",
      "tensor(1091305.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(994731.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(940896., grad_fn=<MseLossBackward0>)\n",
      "tensor(902833.3125, grad_fn=<MseLossBackward0>)\n",
      "tensor(873032.3750, grad_fn=<MseLossBackward0>)\n",
      "tensor(850200.6875, grad_fn=<MseLossBackward0>)\n",
      "tensor(831840.3125, grad_fn=<MseLossBackward0>)\n",
      "tensor(816738.9375, grad_fn=<MseLossBackward0>)\n",
      "tensor(804435.4375, grad_fn=<MseLossBackward0>)\n",
      "tensor(793761.8125, grad_fn=<MseLossBackward0>)\n",
      "tensor(784314.8750, grad_fn=<MseLossBackward0>)\n",
      "tensor(775704.8125, grad_fn=<MseLossBackward0>)\n",
      "tensor(767322.3125, grad_fn=<MseLossBackward0>)\n",
      "tensor(759490.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(752236.3750, grad_fn=<MseLossBackward0>)\n",
      "tensor(745498.9375, grad_fn=<MseLossBackward0>)\n",
      "tensor(739164.6250, grad_fn=<MseLossBackward0>)\n",
      "tensor(733334.0625, grad_fn=<MseLossBackward0>)\n",
      "tensor(727882.8750, grad_fn=<MseLossBackward0>)\n",
      "tensor(722040.4375, grad_fn=<MseLossBackward0>)\n",
      "tensor(716426.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(711162.5625, grad_fn=<MseLossBackward0>)\n",
      "tensor(706212.6875, grad_fn=<MseLossBackward0>)\n",
      "tensor(701461.1875, grad_fn=<MseLossBackward0>)\n",
      "tensor(696879.3125, grad_fn=<MseLossBackward0>)\n",
      "tensor(692512.1875, grad_fn=<MseLossBackward0>)\n",
      "tensor(688136.3750, grad_fn=<MseLossBackward0>)\n",
      "tensor(683743.0625, grad_fn=<MseLossBackward0>)\n",
      "tensor(679634.6250, grad_fn=<MseLossBackward0>)\n",
      "tensor(675829.3125, grad_fn=<MseLossBackward0>)\n",
      "tensor(672368.6875, grad_fn=<MseLossBackward0>)\n",
      "tensor(669138.5625, grad_fn=<MseLossBackward0>)\n",
      "tensor(666121.4375, grad_fn=<MseLossBackward0>)\n",
      "tensor(663207.1875, grad_fn=<MseLossBackward0>)\n",
      "tensor(660485.4375, grad_fn=<MseLossBackward0>)\n",
      "tensor(657288.1250, grad_fn=<MseLossBackward0>)\n",
      "tensor(654677.6250, grad_fn=<MseLossBackward0>)\n",
      "tensor(652124.1250, grad_fn=<MseLossBackward0>)\n",
      "tensor(649548.5625, grad_fn=<MseLossBackward0>)\n",
      "tensor(647124.4375, grad_fn=<MseLossBackward0>)\n",
      "tensor(644835.5625, grad_fn=<MseLossBackward0>)\n",
      "tensor(642673.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(640036.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(637578.1250, grad_fn=<MseLossBackward0>)\n",
      "tensor(635118.8125, grad_fn=<MseLossBackward0>)\n",
      "tensor(632685.6250, grad_fn=<MseLossBackward0>)\n",
      "tensor(630571.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(628695.4375, grad_fn=<MseLossBackward0>)\n",
      "tensor(626882.3750, grad_fn=<MseLossBackward0>)\n",
      "tensor(625200.4375, grad_fn=<MseLossBackward0>)\n",
      "tensor(623587.1250, grad_fn=<MseLossBackward0>)\n",
      "tensor(621929.8125, grad_fn=<MseLossBackward0>)\n",
      "tensor(620327.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(618839.5625, grad_fn=<MseLossBackward0>)\n",
      "tensor(617418.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(616001., grad_fn=<MseLossBackward0>)\n",
      "tensor(614602.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(613221.6250, grad_fn=<MseLossBackward0>)\n",
      "tensor(611778.6875, grad_fn=<MseLossBackward0>)\n",
      "tensor(610368.6250, grad_fn=<MseLossBackward0>)\n",
      "tensor(609095.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(607868.6250, grad_fn=<MseLossBackward0>)\n",
      "tensor(606670.0625, grad_fn=<MseLossBackward0>)\n",
      "tensor(605547., grad_fn=<MseLossBackward0>)\n",
      "tensor(604405.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(603209.8125, grad_fn=<MseLossBackward0>)\n",
      "tensor(602009.6250, grad_fn=<MseLossBackward0>)\n",
      "tensor(600906.0625, grad_fn=<MseLossBackward0>)\n",
      "tensor(599829.1250, grad_fn=<MseLossBackward0>)\n",
      "tensor(598658.4375, grad_fn=<MseLossBackward0>)\n",
      "tensor(597350.6875, grad_fn=<MseLossBackward0>)\n",
      "tensor(596013.8125, grad_fn=<MseLossBackward0>)\n",
      "tensor(594819.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(593755.9375, grad_fn=<MseLossBackward0>)\n",
      "tensor(592754.3125, grad_fn=<MseLossBackward0>)\n",
      "tensor(591835.1875, grad_fn=<MseLossBackward0>)\n",
      "tensor(590970.8125, grad_fn=<MseLossBackward0>)\n",
      "tensor(590106.6875, grad_fn=<MseLossBackward0>)\n",
      "tensor(589280.1875, grad_fn=<MseLossBackward0>)\n",
      "tensor(588389.0625, grad_fn=<MseLossBackward0>)\n",
      "tensor(587288.9375, grad_fn=<MseLossBackward0>)\n",
      "tensor(586189.5625, grad_fn=<MseLossBackward0>)\n",
      "tensor(585250.8750, grad_fn=<MseLossBackward0>)\n",
      "tensor(584195.3125, grad_fn=<MseLossBackward0>)\n",
      "tensor(583257.6875, grad_fn=<MseLossBackward0>)\n",
      "tensor(582374.4375, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-25 14:50:17,766]\u001b[0m Trial 27 finished with value: 889.8110961914062 and parameters: {'n_layers': 3, 'n_h_0': 23, 'n_h_1': 61, 'n_h_2': 34, 'lr': 0.00586695277364326, 'n_epochs': 88143}. Best is trial 23 with value: 871.9281616210938.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(581514.4375, grad_fn=<MseLossBackward0>)\n",
      "Final valid loss: 791763.75\n",
      "#################\n",
      "1\n",
      "Params:\n",
      "          n_layers: 1\n",
      "          n_hidden_units: [26]\n",
      "          lr: 0.0017864622819866562\n",
      "          n_epochs: 90657\n",
      "tensor(9496664., grad_fn=<MseLossBackward0>)\n",
      "tensor(9481816., grad_fn=<MseLossBackward0>)\n",
      "tensor(9469656., grad_fn=<MseLossBackward0>)\n",
      "tensor(9457017., grad_fn=<MseLossBackward0>)\n",
      "tensor(9443874., grad_fn=<MseLossBackward0>)\n",
      "tensor(9430663., grad_fn=<MseLossBackward0>)\n",
      "tensor(9417455., grad_fn=<MseLossBackward0>)\n",
      "tensor(9404260., grad_fn=<MseLossBackward0>)\n",
      "tensor(9391080., grad_fn=<MseLossBackward0>)\n",
      "tensor(9377916., grad_fn=<MseLossBackward0>)\n",
      "tensor(9364779., grad_fn=<MseLossBackward0>)\n",
      "tensor(9351667., grad_fn=<MseLossBackward0>)\n",
      "tensor(9338570., grad_fn=<MseLossBackward0>)\n",
      "tensor(9325498., grad_fn=<MseLossBackward0>)\n",
      "tensor(9312448., grad_fn=<MseLossBackward0>)\n",
      "tensor(9299418., grad_fn=<MseLossBackward0>)\n",
      "tensor(9286407., grad_fn=<MseLossBackward0>)\n",
      "tensor(9273422., grad_fn=<MseLossBackward0>)\n",
      "tensor(9260458., grad_fn=<MseLossBackward0>)\n",
      "tensor(9247515., grad_fn=<MseLossBackward0>)\n",
      "tensor(9234595., grad_fn=<MseLossBackward0>)\n",
      "tensor(9221700., grad_fn=<MseLossBackward0>)\n",
      "tensor(9208821., grad_fn=<MseLossBackward0>)\n",
      "tensor(9195967., grad_fn=<MseLossBackward0>)\n",
      "tensor(9183136., grad_fn=<MseLossBackward0>)\n",
      "tensor(9170326., grad_fn=<MseLossBackward0>)\n",
      "tensor(9157540., grad_fn=<MseLossBackward0>)\n",
      "tensor(9144775., grad_fn=<MseLossBackward0>)\n",
      "tensor(9132032., grad_fn=<MseLossBackward0>)\n",
      "tensor(9119311., grad_fn=<MseLossBackward0>)\n",
      "tensor(9106612., grad_fn=<MseLossBackward0>)\n",
      "tensor(9093929., grad_fn=<MseLossBackward0>)\n",
      "tensor(9081263., grad_fn=<MseLossBackward0>)\n",
      "tensor(9068617., grad_fn=<MseLossBackward0>)\n",
      "tensor(9055993., grad_fn=<MseLossBackward0>)\n",
      "tensor(9043393., grad_fn=<MseLossBackward0>)\n",
      "tensor(9030813., grad_fn=<MseLossBackward0>)\n",
      "tensor(9018254., grad_fn=<MseLossBackward0>)\n",
      "tensor(9005712., grad_fn=<MseLossBackward0>)\n",
      "tensor(8993195., grad_fn=<MseLossBackward0>)\n",
      "tensor(8980699., grad_fn=<MseLossBackward0>)\n",
      "tensor(8968222., grad_fn=<MseLossBackward0>)\n",
      "tensor(8955766., grad_fn=<MseLossBackward0>)\n",
      "tensor(8943327., grad_fn=<MseLossBackward0>)\n",
      "tensor(8930911., grad_fn=<MseLossBackward0>)\n",
      "tensor(8918515., grad_fn=<MseLossBackward0>)\n",
      "tensor(8906141., grad_fn=<MseLossBackward0>)\n",
      "tensor(8893786., grad_fn=<MseLossBackward0>)\n",
      "tensor(8881454., grad_fn=<MseLossBackward0>)\n",
      "tensor(8869144., grad_fn=<MseLossBackward0>)\n",
      "tensor(8856856., grad_fn=<MseLossBackward0>)\n",
      "tensor(8844588., grad_fn=<MseLossBackward0>)\n",
      "tensor(8832341., grad_fn=<MseLossBackward0>)\n",
      "tensor(8820115., grad_fn=<MseLossBackward0>)\n",
      "tensor(8807909., grad_fn=<MseLossBackward0>)\n",
      "tensor(8795723., grad_fn=<MseLossBackward0>)\n",
      "tensor(8783556., grad_fn=<MseLossBackward0>)\n",
      "tensor(8771408., grad_fn=<MseLossBackward0>)\n",
      "tensor(8759280., grad_fn=<MseLossBackward0>)\n",
      "tensor(8747170., grad_fn=<MseLossBackward0>)\n",
      "tensor(8735082., grad_fn=<MseLossBackward0>)\n",
      "tensor(8723011., grad_fn=<MseLossBackward0>)\n",
      "tensor(8710961., grad_fn=<MseLossBackward0>)\n",
      "tensor(8698931., grad_fn=<MseLossBackward0>)\n",
      "tensor(8686919., grad_fn=<MseLossBackward0>)\n",
      "tensor(8674926., grad_fn=<MseLossBackward0>)\n",
      "tensor(8662951., grad_fn=<MseLossBackward0>)\n",
      "tensor(8650856., grad_fn=<MseLossBackward0>)\n",
      "tensor(8638500., grad_fn=<MseLossBackward0>)\n",
      "tensor(8626070., grad_fn=<MseLossBackward0>)\n",
      "tensor(8613621., grad_fn=<MseLossBackward0>)\n",
      "tensor(8601172., grad_fn=<MseLossBackward0>)\n",
      "tensor(8588738., grad_fn=<MseLossBackward0>)\n",
      "tensor(8576318., grad_fn=<MseLossBackward0>)\n",
      "tensor(8563921., grad_fn=<MseLossBackward0>)\n",
      "tensor(8551535., grad_fn=<MseLossBackward0>)\n",
      "tensor(8539174., grad_fn=<MseLossBackward0>)\n",
      "tensor(8526828., grad_fn=<MseLossBackward0>)\n",
      "tensor(8514505., grad_fn=<MseLossBackward0>)\n",
      "tensor(8502199., grad_fn=<MseLossBackward0>)\n",
      "tensor(8489919., grad_fn=<MseLossBackward0>)\n",
      "tensor(8477656., grad_fn=<MseLossBackward0>)\n",
      "tensor(8465414., grad_fn=<MseLossBackward0>)\n",
      "tensor(8453189., grad_fn=<MseLossBackward0>)\n",
      "tensor(8440988., grad_fn=<MseLossBackward0>)\n",
      "tensor(8428799., grad_fn=<MseLossBackward0>)\n",
      "tensor(8416635., grad_fn=<MseLossBackward0>)\n",
      "tensor(8404482., grad_fn=<MseLossBackward0>)\n",
      "tensor(8392357., grad_fn=<MseLossBackward0>)\n",
      "tensor(8380245., grad_fn=<MseLossBackward0>)\n",
      "tensor(8368158., grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-25 14:50:34,158]\u001b[0m Trial 28 finished with value: 2861.944580078125 and parameters: {'n_layers': 1, 'n_h_0': 26, 'lr': 0.0017864622819866562, 'n_epochs': 90657}. Best is trial 23 with value: 871.9281616210938.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final valid loss: 8190726.5\n",
      "#################\n",
      "3\n",
      "Params:\n",
      "          n_layers: 3\n",
      "          n_hidden_units: [17, 47, 26]\n",
      "          lr: 0.037183220524202844\n",
      "          n_epochs: 81475\n",
      "tensor(9497147., grad_fn=<MseLossBackward0>)\n",
      "tensor(704139.6875, grad_fn=<MseLossBackward0>)\n",
      "tensor(630032.6875, grad_fn=<MseLossBackward0>)\n",
      "tensor(557363.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(460855.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(397785.8750, grad_fn=<MseLossBackward0>)\n",
      "tensor(367869.2188, grad_fn=<MseLossBackward0>)\n",
      "tensor(347284.3750, grad_fn=<MseLossBackward0>)\n",
      "tensor(333226.2812, grad_fn=<MseLossBackward0>)\n",
      "tensor(320805.0938, grad_fn=<MseLossBackward0>)\n",
      "tensor(311670.6875, grad_fn=<MseLossBackward0>)\n",
      "tensor(304426.3438, grad_fn=<MseLossBackward0>)\n",
      "tensor(299748.8125, grad_fn=<MseLossBackward0>)\n",
      "tensor(295938.1250, grad_fn=<MseLossBackward0>)\n",
      "tensor(292913.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(290486., grad_fn=<MseLossBackward0>)\n",
      "tensor(288549.6875, grad_fn=<MseLossBackward0>)\n",
      "tensor(286286.6875, grad_fn=<MseLossBackward0>)\n",
      "tensor(284233.6562, grad_fn=<MseLossBackward0>)\n",
      "tensor(281864.6562, grad_fn=<MseLossBackward0>)\n",
      "tensor(278341.2188, grad_fn=<MseLossBackward0>)\n",
      "tensor(274835.6562, grad_fn=<MseLossBackward0>)\n",
      "tensor(270546.9688, grad_fn=<MseLossBackward0>)\n",
      "tensor(265428.3125, grad_fn=<MseLossBackward0>)\n",
      "tensor(259746.6562, grad_fn=<MseLossBackward0>)\n",
      "tensor(255013.1406, grad_fn=<MseLossBackward0>)\n",
      "tensor(251004.1719, grad_fn=<MseLossBackward0>)\n",
      "tensor(246473.1406, grad_fn=<MseLossBackward0>)\n",
      "tensor(241707.1875, grad_fn=<MseLossBackward0>)\n",
      "tensor(236541.8281, grad_fn=<MseLossBackward0>)\n",
      "tensor(232143.9219, grad_fn=<MseLossBackward0>)\n",
      "tensor(227340.1250, grad_fn=<MseLossBackward0>)\n",
      "tensor(223022.3125, grad_fn=<MseLossBackward0>)\n",
      "tensor(218566.0312, grad_fn=<MseLossBackward0>)\n",
      "tensor(213950.5156, grad_fn=<MseLossBackward0>)\n",
      "tensor(208983.9219, grad_fn=<MseLossBackward0>)\n",
      "tensor(204733.8906, grad_fn=<MseLossBackward0>)\n",
      "tensor(200208.6719, grad_fn=<MseLossBackward0>)\n",
      "tensor(196325.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor(192976.1094, grad_fn=<MseLossBackward0>)\n",
      "tensor(190015.0781, grad_fn=<MseLossBackward0>)\n",
      "tensor(187709.3281, grad_fn=<MseLossBackward0>)\n",
      "tensor(185552.3438, grad_fn=<MseLossBackward0>)\n",
      "tensor(182746.6875, grad_fn=<MseLossBackward0>)\n",
      "tensor(180433.0156, grad_fn=<MseLossBackward0>)\n",
      "tensor(178539., grad_fn=<MseLossBackward0>)\n",
      "tensor(176610.6875, grad_fn=<MseLossBackward0>)\n",
      "tensor(175032.8438, grad_fn=<MseLossBackward0>)\n",
      "tensor(173166.1562, grad_fn=<MseLossBackward0>)\n",
      "tensor(171290.6562, grad_fn=<MseLossBackward0>)\n",
      "tensor(168881.9375, grad_fn=<MseLossBackward0>)\n",
      "tensor(165923.2188, grad_fn=<MseLossBackward0>)\n",
      "tensor(163178.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(160813.4844, grad_fn=<MseLossBackward0>)\n",
      "tensor(158716.8594, grad_fn=<MseLossBackward0>)\n",
      "tensor(156326.1406, grad_fn=<MseLossBackward0>)\n",
      "tensor(154284.8594, grad_fn=<MseLossBackward0>)\n",
      "tensor(152277.2031, grad_fn=<MseLossBackward0>)\n",
      "tensor(150362.0156, grad_fn=<MseLossBackward0>)\n",
      "tensor(148369.2812, grad_fn=<MseLossBackward0>)\n",
      "tensor(146493.0312, grad_fn=<MseLossBackward0>)\n",
      "tensor(144760.6562, grad_fn=<MseLossBackward0>)\n",
      "tensor(143006.3906, grad_fn=<MseLossBackward0>)\n",
      "tensor(141486.8906, grad_fn=<MseLossBackward0>)\n",
      "tensor(140079.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(138589.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor(137413.1719, grad_fn=<MseLossBackward0>)\n",
      "tensor(136134.0938, grad_fn=<MseLossBackward0>)\n",
      "tensor(134976.4062, grad_fn=<MseLossBackward0>)\n",
      "tensor(133761.0156, grad_fn=<MseLossBackward0>)\n",
      "tensor(132697.4062, grad_fn=<MseLossBackward0>)\n",
      "tensor(131476.1719, grad_fn=<MseLossBackward0>)\n",
      "tensor(130206.9453, grad_fn=<MseLossBackward0>)\n",
      "tensor(128758.6016, grad_fn=<MseLossBackward0>)\n",
      "tensor(127511.1094, grad_fn=<MseLossBackward0>)\n",
      "tensor(126431.6172, grad_fn=<MseLossBackward0>)\n",
      "tensor(125258.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor(124132.1562, grad_fn=<MseLossBackward0>)\n",
      "tensor(122929.1719, grad_fn=<MseLossBackward0>)\n",
      "tensor(121839.2500, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 3. Create a study object and optimize the objective function.\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "pd.DataFrame.from_dict({\"value\": study.best_trial.values, \"params\": str(\n",
    "    study.best_trial.params)}).to_csv(\"nn_hpo/run_1.csv\", index=False)\n",
    "\n",
    "fig = optuna.visualization.plot_optimization_history(study)\n",
    "# fig.show()\n",
    "fig.write_image(\"nn_hpo/run_1.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=5, values=[894.4140014648438], datetime_start=datetime.datetime(2022, 11, 25, 14, 25, 29, 6298), datetime_complete=datetime.datetime(2022, 11, 25, 14, 25, 31, 569139), params={'n_layers': 1, 'n_h_0': 55, 'lr': 0.4052954218938756, 'n_epochs': 9100}, distributions={'n_layers': IntDistribution(high=5, log=False, low=0, step=1), 'n_h_0': IntDistribution(high=100, log=False, low=1, step=1), 'lr': FloatDistribution(high=0.5, log=False, low=0.001, step=None), 'n_epochs': IntDistribution(high=10000, log=False, low=1000, step=1)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=5, state=TrialState.COMPLETE, value=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95ef66565be0ab37caf8d705f94b2ba6fd3ff1d5242a0930694c635ab854b36c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
